{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q67m9_tVIcT6","executionInfo":{"status":"ok","timestamp":1758365130624,"user_tz":-330,"elapsed":1210,"user":{"displayName":"Yon Row","userId":"08931847390759870653"}},"outputId":"61ca39d4-5c9c-43cb-e78d-fd13d3ea1c6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["0Archive:  /content/Non cattle (2).zip\n","   creating: /content/Non cattle/\n","  inflating: /content/Non cattle/Dog.png  \n","  inflating: /content/Non cattle/Screenshot 2025-09-20 161316.png  \n"]}],"source":["!unzip \"/content/Non cattle (2).zip\" -d \"/content/\" # Should show your 5 breed folders"]},{"cell_type":"code","source":["# Final Breed Classification by Pashuvision\n","\"\"\"\n","train_breed_final.py\n","Same pipeline as #final trial, but with post-hoc calibration + prob averaging\n","⇒ higher confidence, identical accuracy.\n","\"\"\"\n","import os, json, time, torch, torchvision, numpy as np, shutil, pandas as pd\n","from pathlib import Path\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import datasets, models\n","import torchvision.transforms as T\n","from PIL import Image\n","from torch.amp import autocast, GradScaler\n","from timm.data.auto_augment import rand_augment_transform\n","from timm.data.mixup import Mixup\n","from sklearn.utils.class_weight import compute_class_weight\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using {device}\")\n","\n","# ---------- CONFIG ----------\n","train_dir      = \"/content/Final Dataset/train\"\n","val_dir        = \"/content/Final Dataset/val\"\n","UNLABELLED_DIR = \"/content/unlabelled_images\"\n","PSEUDO_CSV     = \"/content/pseudo_labels.csv\"\n","SAVE_BEST      = \"/content/best_model.pth\"\n","SAVE_FINAL     = \"/content/breed_model_efficientnet_finetuned.pth\"\n","SAVE_LABELS    = \"/content/breed_names.json\"\n","CAL_TEMP_FILE  = \"/content/cal_temp.json\"\n","\n","SOFT_THR       = 0.90\n","TEMP           = 1.0          # will be overwritten by calibrated value\n","RETRAIN_EPOCHS = 5\n","mean, std      = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n","\n","# ---------- transforms ----------\n","rand_aug = rand_augment_transform('rand-m7-mstd0.5', {})\n","train_tf = T.Compose([T.Resize((224, 224)), rand_aug, T.ToTensor(), T.Normalize(mean, std)])\n","unlabelled_tf = T.Compose([\n","    T.Resize(342), T.FiveCrop(256),\n","    T.Lambda(lambda crops: torch.stack([T.ToTensor()(c) for c in crops])),\n","    T.Normalize(mean, std)\n","])\n","val_tf = unlabelled_tf        # same as before\n","\n","# ---------- datasets ----------\n","train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n","val_ds   = datasets.ImageFolder(val_dir,   transform=val_tf)\n","breed_names = train_ds.classes\n","train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n","val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=2, pin_memory=True)\n","\n","# ---------- mixup ----------\n","mixup_fn = Mixup(mixup_alpha=0.1, cutmix_alpha=0.2, prob=1.0,\n","                 num_classes=len(breed_names), label_smoothing=0.05)\n","\n","# ---------- model ----------\n","class Head(nn.Module):\n","    def __init__(self, in_features, n_classes, drop=0.2):\n","        super().__init__()\n","        self.drop = nn.Dropout(drop)\n","        self.fc   = nn.Linear(in_features, n_classes)\n","        self.eval_drop = True\n","    def forward(self, x):\n","        if self.eval_drop or self.training:\n","            x = self.drop(x)\n","        return self.fc(x)\n","\n","model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n","model.classifier = Head(model.classifier[1].in_features, len(breed_names))\n","model = model.to(device)\n","\n","# ---------- freeze ----------\n","for p in model.parameters(): p.requires_grad = False\n","for p in model.classifier.parameters(): p.requires_grad = True\n","\n","# ---------- class weights ----------\n","labels = train_ds.targets\n","weights = torch.tensor(\n","    compute_class_weight('balanced', classes=np.arange(len(breed_names)), y=labels),\n","    dtype=torch.float, device=device)\n","\n","# ---------- optim ----------\n","optimizer = optim.AdamW(model.classifier.parameters(), lr=3e-3, weight_decay=5e-3)\n","scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","                optimizer, T_0=len(train_loader)*5, T_mult=1, eta_min=1e-6)\n","scaler = GradScaler('cuda')\n","\n","# ---------- helpers ----------\n","def unfreeze_and_add(stage, lr):\n","    frozen = []\n","    for name, module in model.features.named_children():\n","        if int(name) >= stage:\n","            for p in module.parameters():\n","                if not p.requires_grad:\n","                    p.requires_grad = True\n","                    frozen.append(p)\n","    if frozen:\n","        optimizer.add_param_group({'params': frozen, 'lr': lr})\n","\n","# ---------- global metrics ----------\n","best_val_loss = 1e9\n","patience = 15\n","pat_counter = 0\n","accum = 2\n","grad_clip = 1.0\n","\n","\n","#  1. MAIN TRAINING  (unchanged)\n","def main_training():\n","    global best_val_loss, pat_counter\n","    for epoch in range(30):\n","        print(f\"\\n-----  Epoch {epoch+1}/30 -----\")\n","        if epoch == 3: unfreeze_and_add(6, 3e-4)\n","        if epoch == 6: unfreeze_and_add(4, 1e-4)\n","        if epoch == 9: unfreeze_and_add(0, 5e-5)\n","\n","        criterion = nn.CrossEntropyLoss(weight=weights if epoch < 10 else None, label_smoothing=0.05)\n","\n","        model.train()\n","        running = 0.\n","        for i, (x, y) in enumerate(train_loader):\n","            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n","            x, y = mixup_fn(x, y)\n","            with autocast('cuda'):\n","                out = model(x)\n","                loss = criterion(out, y) / accum\n","            scaler.scale(loss).backward()\n","            if (i+1) % accum == 0 or i+1 == len(train_loader):\n","                scaler.unscale_(optimizer)\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","                scaler.step(optimizer); scaler.update(); optimizer.zero_grad(set_to_none=True)\n","            running += loss.item() * accum\n","        print(f\" Train Loss: {running/len(train_loader):.4f}\")\n","\n","        # ---- validate ----\n","        model.eval()\n","        val_loss, correct, total = 0., 0, 0\n","        with torch.no_grad():\n","            for x, y in val_loader:\n","                B = y.size(0)\n","                x = x.view(-1, 3, 256, 256).to(device)\n","                y = y.to(device)\n","                with autocast('cuda'):\n","                    # NEW: average probabilities, not logits\n","                    prob = torch.softmax(model(x), 1).view(5, B, -1).mean(0)\n","                    prob_flip = torch.softmax(model(torch.flip(x, dims=[-1])), 1).view(5, B, -1).mean(0)\n","                    prob = (prob + prob_flip) / 2\n","                    val_loss += nn.CrossEntropyLoss()(torch.log(prob + 1e-8), y).item()\n","                pred = prob.argmax(1)\n","                correct += (pred == y).sum().item()\n","                total += B\n","        val_loss /= len(val_loader)\n","        val_acc = 100 * correct / total\n","        print(f\" Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n","\n","        with open(SAVE_BEST.replace(\".pth\", \"_val_acc.txt\"), \"w\") as f:\n","            f.write(f\"{val_acc:.2f}%\")\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), SAVE_BEST)\n","            pat_counter = 0\n","            print(f\" New best model saved (val_loss={val_loss:.4f})\")\n","        else:\n","            pat_counter += 1\n","            if pat_counter >= patience:\n","                print(\" Early stopping triggered\")\n","                break\n","        scheduler.step()\n","\n","    model.load_state_dict(torch.load(SAVE_BEST))\n","    torch.save(model, SAVE_FINAL)\n","    with open(SAVE_LABELS, \"w\") as f:\n","        json.dump(breed_names, f)\n","    print(\" Main training finished – best model saved\")\n","\n","#  2. TEMPERATURE CALIBRATION (new)\n","def calibrate_temperature():\n","    model.eval()\n","    logits_list, labels_list = [], []\n","    with torch.no_grad():\n","        for x, y in val_loader:\n","            B = y.size(0)\n","            x = x.view(-1, 3, 256, 256).to(device)\n","            y = y.to(device)\n","            prob = torch.softmax(model(x), 1).view(5, B, -1).mean(0)\n","            prob_flip = torch.softmax(model(torch.flip(x, dims=[-1])), 1).view(5, B, -1).mean(0)\n","            prob = (prob + prob_flip) / 2\n","            logit = torch.log(prob + 1e-8)            # calibrated logit\n","            logits_list.append(logit)\n","            labels_list.append(y)\n","    logits = torch.cat(logits_list)   # [N, C]\n","    labels = torch.cat(labels_list)   # [N]\n","\n","    def ece(p, y, n_bins=15):\n","        bin_boundaries = torch.linspace(0,1,n_bins+1)\n","        bin_lowers = bin_boundaries[:-1]\n","        bin_uppers = bin_boundaries[1:]\n","        conf, pred = p.max(1)\n","        acc = pred.eq(y).float()\n","        ece = 0.\n","        for bl, bu in zip(bin_lowers, bin_uppers):\n","            in_bin = conf.gt(bl) * conf.le(bu)\n","            prop = in_bin.float().mean()\n","            if prop > 0:\n","                acc_bin = acc[in_bin].mean()\n","                conf_bin = conf[in_bin].mean()\n","                ece += torch.abs(acc_bin - conf_bin) * prop\n","        return ece\n","\n","    def opt_temp(logits, labels, t_min=0.2, t_max=3.0, steps=50):\n","        best_t, best_ece = 1.0, 1e6\n","        for t in torch.linspace(t_min, t_max, steps):\n","            p = torch.softmax(logits/t, 1)\n","            e = ece(p, labels)\n","            if e < best_ece:\n","                best_ece, best_t = e, t.item()\n","        return best_t\n","\n","    T_cal = opt_temp(logits, labels)\n","    json.dump({'T': T_cal}, open(CAL_TEMP_FILE, 'w'))\n","    print(f' Calibrated temperature = {T_cal:.3f}')\n","\n","\n","#  3. PSEUDO + HUMAN-IN-THE-LOOP  (confidence fix inside)\n","def predict_image(image_path, temp=None):\n","    if temp is None:\n","        if os.path.exists(CAL_TEMP_FILE):\n","            temp = json.load(open(CAL_TEMP_FILE))['T']\n","        else:\n","            temp = 1.0\n","    model.eval()\n","    model.classifier.eval_drop = False   # <- deterministic\n","    img = Image.open(image_path).convert('RGB')\n","    crops = unlabelled_tf(img).to(device)\n","    with torch.no_grad():\n","        with autocast('cuda'):\n","            # average probabilities\n","            prob = torch.softmax(model(crops) / temp, 1).mean(0)\n","            prob_flip = torch.softmax(model(torch.flip(crops, dims=[-1])) / temp, 1).mean(0)\n","            prob = (prob + prob_flip) / 2\n","    top3 = torch.topk(prob, k=3)\n","    return [(breed_names[i], float(p)) for i, p in zip(top3.indices, top3.values)], prob.cpu()\n","\n","def worker_choice(image_path, top3):\n","    print(f\"\\n Image: {image_path}\")\n","    for idx, (b, p) in enumerate(top3, 1):\n","        print(f\"  {idx}. {b}  ({p*100:.1f}%)\")\n","    while True:\n","        try:\n","            choice = input(\" Choose 1-3 (or 0 to skip): \").strip()\n","            if choice == \"0\":\n","                return None\n","            choice = int(choice)\n","            if 1 <= choice <= 3:\n","                return top3[choice-1][0]\n","            else:\n","                print(\" Please enter 0, 1, 2, or 3.\")\n","        except ValueError:\n","            print(\"Invalid input – please enter a number.\")\n","\n","def create_pseudo_csv():\n","    unlabelled_path = Path(UNLABELLED_DIR)\n","    if not unlabelled_path.exists():\n","        print(f\" Unlabelled directory not found: {UNLABELLED_DIR}\")\n","        pd.DataFrame(columns=['file', 'label', 'confidence', 'type']).to_csv(PSEUDO_CSV, index=False)\n","        return pd.DataFrame()\n","\n","    image_files = list(unlabelled_path.rglob(\"*.[jJ][pP][gG]\")) + \\\n","                  list(unlabelled_path.rglob(\"*.[jJ][pP][eE][gG]\")) + \\\n","                  list(unlabelled_path.rglob(\"*.[pP][nN][gG]\"))\n","\n","    if len(image_files) == 0:\n","        print(f\" No images found in {UNLABELLED_DIR}\")\n","        pd.DataFrame(columns=['file', 'label', 'confidence', 'type']).to_csv(PSEUDO_CSV, index=False)\n","        return pd.DataFrame()\n","\n","    print(f\" Found {len(image_files)} images to label...\")\n","    records = []\n","\n","    existing_files = set()\n","    if os.path.exists(PSEUDO_CSV):\n","        try:\n","            existing_df = pd.read_csv(PSEUDO_CSV)\n","            existing_files = set(existing_df['file'].tolist())\n","        except:\n","            pass\n","\n","    for img_path in image_files:\n","        if str(img_path) in existing_files:\n","            print(f\"⏭ Already labeled: {img_path.name}\")\n","            continue\n","\n","        try:\n","            top3, soft_prob = predict_image(img_path)\n","            best_breed, best_conf = top3[0]\n","\n","            if best_conf >= SOFT_THR:\n","                records.append({\n","                    'file': str(img_path),\n","                    'label': best_breed,\n","                    'confidence': best_conf,\n","                    'type': 'pseudo'\n","                })\n","                print(f\" Auto-labeled: {img_path.name} → {best_breed} ({best_conf:.2f})\")\n","            else:\n","                chosen = worker_choice(img_path, top3)\n","                if chosen is not None:\n","                    records.append({\n","                        'file': str(img_path),\n","                        'label': chosen,\n","                        'confidence': 1.0,\n","                        'type': 'human'\n","                    })\n","                    print(f\" Human-labeled: {img_path.name} → {chosen}\")\n","                else:\n","                    print(f\" Skipped: {img_path.name}\")\n","\n","        except Exception as e:\n","            print(f\" Error processing {img_path}: {e}\")\n","            continue\n","\n","    if os.path.exists(PSEUDO_CSV) and len(records) > 0:\n","        try:\n","            existing_df = pd.read_csv(PSEUDO_CSV)\n","            new_df = pd.DataFrame(records)\n","            df = pd.concat([existing_df, new_df], ignore_index=True)\n","        except:\n","            df = pd.DataFrame(records)\n","    else:\n","        df = pd.DataFrame(records)\n","\n","    df.to_csv(PSEUDO_CSV, index=False)\n","    print(f\" CSV saved → {len(df)} total labels collected\")\n","    return df\n","\n","\n","#  4. SOFT-HARD DATASET + RETRAIN  (unchanged)\n","class SoftHardDataset(Dataset):\n","    def __init__(self, csv_file, root, transform, class_to_idx):\n","        if not os.path.exists(csv_file):\n","            self.samples = []\n","            return\n","        try:\n","            self.df = pd.read_csv(csv_file)\n","        except pd.errors.EmptyDataError:\n","            self.df = pd.DataFrame()\n","        self.root = root\n","        self.transform = transform\n","        self.class_to_idx = class_to_idx\n","        self.num_classes = len(class_to_idx)\n","        self.samples = []\n","        if len(self.df) > 0:\n","            for _, row in self.df.iterrows():\n","                self.samples.append((row['file'], row['label'], row['confidence'], row['type']))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        path, label, conf, typ = self.samples[idx]\n","        img = Image.open(path).convert('RGB')\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        # >>> FIX: Always return a tensor of shape [num_classes] <<<\n","        target = torch.zeros(self.num_classes)\n","\n","        label_idx = self.class_to_idx[label]\n","\n","        if typ == 'pseudo':\n","            target[label_idx] = conf\n","        else:  # human\n","            target[label_idx] = 1.0  # One-hot encoding\n","\n","        return img, target.float()\n","\n","def retrain_with_new_data(extra_epochs=RETRAIN_EPOCHS):\n","    global accum, grad_clip\n","\n","    print(\"\\n Checking for pseudo-labels...\")\n","\n","    # Safety check: if CSV doesn't exist or is empty, skip\n","    if not os.path.exists(PSEUDO_CSV):\n","        print(\" Pseudo-labels CSV not found — skipping retraining.\")\n","        return\n","\n","    try:\n","        df = pd.read_csv(PSEUDO_CSV)\n","    except pd.errors.EmptyDataError:\n","        print(\"Pseudo-labels CSV is empty — skipping retraining.\")\n","        return\n","\n","    if len(df) == 0:\n","        print(\" No pseudo-labels collected — skipping retraining.\")\n","        return\n","\n","    print(f\" Found {len(df)} pseudo/human labels — starting retraining...\")\n","\n","    merged_root = \"/content/merged_train\"\n","    os.makedirs(merged_root, exist_ok=True)\n","\n","    # Copy original training data\n","    os.system(f\"cp -r {train_dir}/* {merged_root}/ 2>/dev/null || echo 'Original data copied'\")\n","\n","    # Copy pseudo-labeled images into breed folders\n","    for _, row in df.iterrows():\n","        src = Path(row['file'])\n","        breed = row['label']\n","        breed_dir = Path(merged_root) / breed\n","        breed_dir.mkdir(exist_ok=True)\n","        dst = breed_dir / src.name\n","        if not dst.exists():\n","            shutil.copy(src, dst)\n","\n","    # Create dataset and loader\n","    merged_ds = SoftHardDataset(PSEUDO_CSV, merged_root, transform=train_tf,\n","                                class_to_idx=train_ds.class_to_idx)\n","    if len(merged_ds) == 0:\n","        print(\" Merged dataset is empty — skipping retraining.\")\n","        return\n","\n","    merged_loader = DataLoader(merged_ds, batch_size=16, shuffle=True,\n","                               num_workers=2, pin_memory=True)\n","\n","    # FIX: Create FRESH optimizer (don't add_param_group)\n","    optimizer = optim.AdamW([\n","        {'params': model.classifier.parameters(), 'lr': 1e-4},\n","        {'params': model.features.parameters(), 'lr': 1e-5}  # Lower LR for backbone\n","    ], weight_decay=5e-3)\n","\n","    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","                    optimizer, T_0=len(merged_loader)*3, T_mult=1, eta_min=1e-6)\n","\n","    # Custom criterion for soft/hard labels\n","    def criterion(out, y):\n","        if y.dtype is torch.float32:\n","            return -torch.sum(y * torch.log_softmax(out, dim=1), dim=1).mean()\n","        else:\n","            return nn.CrossEntropyLoss()(out, y)\n","\n","    # Retrain loop\n","    for epoch in range(extra_epochs):\n","        print(f\"\\n+++ Pseudo Epoch {epoch+1}/{extra_epochs} +++\")\n","        model.train()\n","        running = 0.\n","        for x, y in merged_loader:\n","            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n","            with autocast('cuda'):\n","                out = model(x)\n","                loss = criterion(out, y) / accum\n","            scaler.scale(loss).backward()\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","            scaler.step(optimizer); scaler.update(); optimizer.zero_grad(set_to_none=True)\n","            running += loss.item() * accum\n","        print(f\"Merged Loss: {running/len(merged_loader):.4f}\")\n","\n","    torch.save(model, \"/content/model_after_pseudo.pth\")\n","    print(\" Pseudo-training finished – model saved\")\n","\n","    def criterion(out, y):\n","        if y.dtype is torch.float32:\n","            return -torch.sum(y * torch.log_softmax(out, dim=1), dim=1).mean()\n","        else:\n","            return nn.CrossEntropyLoss()(out, y)\n","\n","    for epoch in range(extra_epochs):\n","        print(f\"\\n+++  Pseudo Epoch {epoch+1}/{extra_epochs} +++\")\n","        model.train()\n","        running = 0.\n","        for x, y in merged_loader:\n","            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n","            with autocast('cuda'):\n","                out = model(x)\n","                loss = criterion(out, y) / accum\n","            scaler.scale(loss).backward()\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","            scaler.step(optimizer); scaler.update(); optimizer.zero_grad(set_to_none=True)\n","            running += loss.item() * accum\n","        print(f\" Merged Loss: {running/len(merged_loader):.4f}\")\n","\n","    torch.save(model, \"/content/model_after_pseudo.pth\")\n","    print(\"Pseudo-training finished – model saved\")\n","#5. PRODUCTION: PREDICT + AUTO-LABEL + HUMAN FEEDBACK\n","def predict_and_auto_label(image_path, conf_threshold=0.78):\n","    print(f\"\\n🔍 PRODUCTION MODE: Analyzing {image_path}\")\n","    global model, breed_names\n","    if 'model' not in globals() or model is None:\n","        print(\"Loading model...\")\n","        model = torch.load(SAVE_FINAL)\n","        model = model.to(device)\n","        model.eval()\n","        model.classifier.eval_drop = False\n","        with open(SAVE_LABELS, \"r\") as f:\n","            breed_names = json.load(f)\n","        print(\" Model loaded.\")\n","\n","    val_acc = \"N/A\"\n","    val_acc_file = SAVE_BEST.replace(\".pth\", \"_val_acc.txt\")\n","    if os.path.exists(val_acc_file):\n","        try:\n","            with open(val_acc_file, \"r\") as f:\n","                val_acc = f.read().strip()\n","        except: pass\n","\n","    top3, prob = predict_image(image_path)\n","    best_breed, best_conf = top3[0]\n","\n","    print(f\" TOP PREDICTION: {best_breed} ({best_conf:.4f})\")\n","    print(f\" LAST KNOWN VAL ACCURACY: {val_acc}\")\n","    print(\"\\n TOP 3 BREEDS:\")\n","    for idx, (breed, conf) in enumerate(top3, 1):\n","        print(f\"  {idx}. {breed} ({conf:.4f})\")\n","\n","    chosen_label = None\n","\n","    if best_conf >= conf_threshold:\n","        print(f\"\\n AUTO-LABELING (Confidence {best_conf:.4f} >= {conf_threshold})\")\n","        chosen_label = best_breed\n","    else:\n","        print(f\"\\n LOW CONFIDENCE ({best_conf:.4f} < {conf_threshold}) — PLEASE CHOOSE:\")\n","        print(\"  1-3: Select from top predictions above\")\n","        print(\"  4. Other (type breed name)\")\n","        print(\"  0. Skip (do not label)\")\n","\n","        while True:\n","            try:\n","                choice = input(\"\\n Your choice (0-4): \").strip()\n","                if choice == \"0\":\n","                    print(\"⏭ Skipped — no label saved.\")\n","                    return None, None\n","                elif choice in [\"1\", \"2\", \"3\"]:\n","                    chosen_label = top3[int(choice) - 1][0]\n","                    print(f\" You chose: {chosen_label}\")\n","                    break\n","                elif choice == \"4\":\n","                    while True:\n","                        custom_breed = input(\" Enter breed name: \").strip()\n","                        if custom_breed in breed_names:\n","                            chosen_label = custom_breed\n","                            print(f\" Valid breed: {chosen_label}\")\n","                            break\n","                        else:\n","                            print(f\" '{custom_breed}' not in known breeds: {breed_names}\")\n","                            retry = input(\"Try again? (y/n): \").strip().lower()\n","                            if retry != 'y':\n","                                print(\"⏭ Skipped — no label saved.\")\n","                                return None, None\n","                    break\n","                else:\n","                    print(\" Please enter 0, 1, 2, 3, or 4.\")\n","            except KeyboardInterrupt:\n","                print(\"\\n⏭ Interrupted — no label saved.\")\n","                return None, None\n","            except Exception as e:\n","                print(f\" Error: {e} — try again.\")\n","\n","    if chosen_label is not None:\n","        Path(UNLABELLED_DIR).mkdir(parents=True, exist_ok=True)\n","        src_path = Path(image_path)\n","        dest_name = src_path.name\n","        dest_path = Path(UNLABELLED_DIR) / dest_name\n","        counter = 1\n","        while dest_path.exists():\n","            dest_name = f\"{src_path.stem}_{counter}{src_path.suffix}\"\n","            dest_path = Path(UNLABELLED_DIR) / dest_name\n","            counter += 1\n","\n","        shutil.copy(image_path, dest_path)\n","        print(f\" Saved to: {dest_path}\")\n","\n","        label_type = \"pseudo\" if best_conf >= conf_threshold else \"human\"\n","        record = {\n","            'file': str(dest_path),\n","            'label': chosen_label,\n","            'confidence': best_conf if label_type == \"pseudo\" else 1.0,\n","            'type': label_type\n","        }\n","\n","        if os.path.exists(PSEUDO_CSV):\n","            try:\n","                df = pd.read_csv(PSEUDO_CSV)\n","                new_df = pd.DataFrame([record])\n","                df = pd.concat([df, new_df], ignore_index=True)\n","            except:\n","                df = pd.DataFrame([record])\n","        else:\n","            df = pd.DataFrame([record])\n","\n","        df.to_csv(PSEUDO_CSV, index=False)\n","        print(f\" Added to {PSEUDO_CSV} → Ready for next retraining!\")\n","        return chosen_label, best_conf\n","\n","    return None, None\n","\n","\n","#  6. RUN PIPELINE\n","if __name__ == \"__main__\":\n","    print(\" Starting full training pipeline...\")\n","    main_training()\n","    calibrate_temperature()\n","    df = create_pseudo_csv()\n","    if len(df) > 0:\n","        retrain_with_new_data()\n","    else:\n","        print(\" Skipping retraining — no new labels collected.\")\n","\n","    print(\"\\n PIPELINE COMPLETE!\")\n","    print(\" Final model: /content/breed_model_efficientnet_finetuned.pth\")\n","    print(\"  Breed names: /content/breed_names.json\")\n","    if os.path.exists(\"/content/model_after_pseudo.pth\"):\n","        print(\" Upgraded model: /content/model_after_pseudo.pth\")\n","\n","    print(\"\\n TIP: To label NEW images later, run:\")\n","    print(\"   df = label_new_images_only()\")\n","    print(\"   if len(df) > 0:\")\n","    print(\"       retrain_with_new_data()\")\n","\n","    print(\"\\n PRODUCTION TIP: To predict + auto-label/human-label a new image, run:\")\n","    print(\"   breed, conf = predict_and_auto_label('path/to/your/image.jpg', conf_threshold=0.92)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PALUHKHT1nr","executionInfo":{"status":"ok","timestamp":1758362491334,"user_tz":-330,"elapsed":52518,"user":{"displayName":"Yon Row","userId":"08931847390759870653"}},"outputId":"62c38e79-0441-49de-ec28-d1c04e0831e4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda\n"," Starting full training pipeline...\n","\n","-----  Epoch 1/30 -----\n"," Train Loss: 1.9842\n"," Val Loss: 1.1808 | Val Acc: 78.10%\n"," New best model saved (val_loss=1.1808)\n","\n","-----  Epoch 2/30 -----\n"," Train Loss: 1.7351\n"," Val Loss: 1.0484 | Val Acc: 85.19%\n"," New best model saved (val_loss=1.0484)\n","\n","-----  Epoch 3/30 -----\n"," Train Loss: 1.7021\n"," Val Loss: 1.0418 | Val Acc: 88.41%\n"," New best model saved (val_loss=1.0418)\n","\n","-----  Epoch 4/30 -----\n"," Train Loss: 1.6059\n"," Val Loss: 0.8075 | Val Acc: 87.12%\n"," New best model saved (val_loss=0.8075)\n","\n","-----  Epoch 5/30 -----\n"," Train Loss: 1.4705\n"," Val Loss: 0.7177 | Val Acc: 90.82%\n"," New best model saved (val_loss=0.7177)\n","\n","-----  Epoch 6/30 -----\n"," Train Loss: 1.3675\n"," Val Loss: 0.6915 | Val Acc: 90.02%\n"," New best model saved (val_loss=0.6915)\n","\n","-----  Epoch 7/30 -----\n"," Train Loss: 1.3451\n"," Val Loss: 0.6881 | Val Acc: 92.91%\n"," New best model saved (val_loss=0.6881)\n","\n","-----  Epoch 8/30 -----\n"," Train Loss: 1.2901\n"," Val Loss: 0.6291 | Val Acc: 90.82%\n"," New best model saved (val_loss=0.6291)\n","\n","-----  Epoch 9/30 -----\n"," Train Loss: 1.2336\n"," Val Loss: 0.6291 | Val Acc: 93.88%\n"," New best model saved (val_loss=0.6291)\n","\n","-----  Epoch 10/30 -----\n"," Train Loss: 1.2246\n"," Val Loss: 0.6713 | Val Acc: 90.02%\n","\n","-----  Epoch 11/30 -----\n"," Train Loss: 1.1953\n"," Val Loss: 0.5700 | Val Acc: 91.63%\n"," New best model saved (val_loss=0.5700)\n","\n","-----  Epoch 12/30 -----\n"," Train Loss: 1.1155\n"," Val Loss: 0.5251 | Val Acc: 92.59%\n"," New best model saved (val_loss=0.5251)\n","\n","-----  Epoch 13/30 -----\n"," Train Loss: 1.0929\n"," Val Loss: 0.5899 | Val Acc: 95.65%\n","\n","-----  Epoch 14/30 -----\n"," Train Loss: 1.0965\n"," Val Loss: 0.5748 | Val Acc: 95.33%\n","\n","-----  Epoch 15/30 -----\n"," Train Loss: 1.0834\n"," Val Loss: 0.5317 | Val Acc: 95.17%\n","\n","-----  Epoch 16/30 -----\n"," Train Loss: 1.0232\n"," Val Loss: 0.4840 | Val Acc: 94.85%\n"," New best model saved (val_loss=0.4840)\n","\n","-----  Epoch 17/30 -----\n"," Train Loss: 1.0361\n"," Val Loss: 0.5818 | Val Acc: 94.85%\n","\n","-----  Epoch 18/30 -----\n"," Train Loss: 1.1476\n"," Val Loss: 0.5667 | Val Acc: 93.40%\n","\n","-----  Epoch 19/30 -----\n"," Train Loss: 1.0959\n"," Val Loss: 0.5031 | Val Acc: 95.49%\n","\n","-----  Epoch 20/30 -----\n"," Train Loss: 1.0712\n"," Val Loss: 0.5584 | Val Acc: 93.08%\n","\n","-----  Epoch 21/30 -----\n"," Train Loss: 0.9573\n"," Val Loss: 0.5219 | Val Acc: 94.69%\n","\n","-----  Epoch 22/30 -----\n"," Train Loss: 1.0454\n"," Val Loss: 0.5595 | Val Acc: 93.72%\n","\n","-----  Epoch 23/30 -----\n"," Train Loss: 1.0173\n"," Val Loss: 0.5956 | Val Acc: 92.11%\n","\n","-----  Epoch 24/30 -----\n"," Train Loss: 0.9872\n"," Val Loss: 0.5760 | Val Acc: 95.17%\n","\n","-----  Epoch 25/30 -----\n"," Train Loss: 0.9970\n"," Val Loss: 0.5875 | Val Acc: 93.40%\n","\n","-----  Epoch 26/30 -----\n"," Train Loss: 0.9748\n"," Val Loss: 0.5861 | Val Acc: 94.69%\n","\n","-----  Epoch 27/30 -----\n"," Train Loss: 1.0052\n"," Val Loss: 0.5040 | Val Acc: 94.36%\n","\n","-----  Epoch 28/30 -----\n"," Train Loss: 0.9888\n"," Val Loss: 0.5443 | Val Acc: 95.33%\n","\n","-----  Epoch 29/30 -----\n"," Train Loss: 1.0527\n"," Val Loss: 0.5720 | Val Acc: 92.27%\n","\n","-----  Epoch 30/30 -----\n"," Train Loss: 0.9943\n"," Val Loss: 0.5583 | Val Acc: 94.52%\n"," Main training finished – best model saved\n"," Calibrated temperature = 0.257\n"," No images found in /content/unlabelled_images\n"," Skipping retraining — no new labels collected.\n","\n"," PIPELINE COMPLETE!\n"," Final model: /content/breed_model_efficientnet_finetuned.pth\n","  Breed names: /content/breed_names.json\n","\n"," TIP: To label NEW images later, run:\n","   df = label_new_images_only()\n","   if len(df) > 0:\n","       retrain_with_new_data()\n","\n"," PRODUCTION TIP: To predict + auto-label/human-label a new image, run:\n","   breed, conf = predict_and_auto_label('path/to/your/image.jpg', conf_threshold=0.92)\n"]}]},{"cell_type":"code","source":["predict_and_auto_label(\"/content/Non cattle/Screenshot 2025-09-20 161316.png\", 0.78)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Afv5I9ZRezm-","executionInfo":{"status":"ok","timestamp":1758369675428,"user_tz":-330,"elapsed":588,"user":{"displayName":"Yon Row","userId":"08931847390759870653"}},"outputId":"99bf18a9-5371-4d50-dff5-e13e39ea2f52"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🔍 PRODUCTION MODE: Analyzing /content/Non cattle/Screenshot 2025-09-20 161316.png\n"," TOP PREDICTION: Ayrshire (0.8030)\n"," LAST KNOWN VAL ACCURACY: 94.52%\n","\n"," TOP 3 BREEDS:\n","  1. Ayrshire (0.8030)\n","  2. Jersey (0.1956)\n","  3. Sahiwal (0.0008)\n","\n"," AUTO-LABELING (Confidence 0.8030 >= 0.78)\n"," Saved to: /content/unlabelled_images/Screenshot 2025-09-20 161316_3.png\n"," Added to /content/pseudo_labels.csv → Ready for next retraining!\n"]},{"output_type":"execute_result","data":{"text/plain":["('Ayrshire', 0.8030022382736206)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["retrain_with_new_data()"],"metadata":{"id":"PV54o2SWfLFh","executionInfo":{"status":"ok","timestamp":1758363371571,"user_tz":-330,"elapsed":899,"user":{"displayName":"Yon Row","userId":"08931847390759870653"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vye0pbNqmQuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"h1kmSvqNmQw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JdETFbspmQzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vFh0Y_FUmQ1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DgOvYOsjmQ5H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SiW3mOLsmQ7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qLFeluzgmQ-Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GHd5geGomRBP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QfhdSDermREI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pPnlsSjPmRGw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qpjL4EoKmRJg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"quD6GOyJmRMQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1lkB5XSYmRPH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KdP8LcR5mRRf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6mZSRVTVmRUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JLq8GrIrmRXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Thc0BONpmRZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# demo_images\n","import shutil\n","from pathlib import Path\n","import random\n","\n","# Get all validation images, grouped by breed\n","breed_images = {}\n","val_path = Path(\"/content/Final Dataset/val\")\n","\n","for breed_dir in val_path.iterdir():\n","    if breed_dir.is_dir():\n","        # Get all JPG/JPEG/PNG in this breed folder\n","        images = list(breed_dir.rglob(\"*.[jJ][pP][gG]\")) + \\\n","                 list(breed_dir.rglob(\"*.[jJ][pP][eE][gG]\")) + \\\n","                 list(breed_dir.rglob(\"*.[pP][nN][gG]\"))\n","        if images:\n","            breed_images[breed_dir.name] = images\n","\n","print(f\"Found {len(breed_images)} breeds: {list(breed_images.keys())}\")\n","\n","# Shuffle images within each breed\n","for breed in breed_images:\n","    random.shuffle(breed_images[breed])\n","\n","# Create demo folder\n","demo_dir = Path(\"/content/demo_images\")\n","demo_dir.mkdir(exist_ok=True)\n","\n","demo_saved = 0\n","max_per_breed = 2  # Max 2 images per breed → ensures diversity\n","breed_count = {breed: 0 for breed in breed_images}\n","\n","print(\"\\n🔍 Building diverse demo set (confidence 90-98%)...\")\n","\n","# Round-robin sampling from each breed\n","while demo_saved < 10 and any(breed_images.values()):\n","    for breed in list(breed_images.keys()):\n","        if breed_count[breed] >= max_per_breed:\n","            continue  # Skip if we already have enough from this breed\n","        if not breed_images[breed]:\n","            continue  # Skip if no more images in this breed\n","\n","        # Take one image from this breed\n","        img_path = breed_images[breed].pop()\n","        try:\n","            top3, prob = predict_image(str(img_path))\n","            best_breed, best_conf = top3[0]\n","            true_breed = breed  # Since it's from this breed's folder\n","\n","            # >>> ONLY ADD IF CONFIDENCE BETWEEN 90% AND 98% AND CORRECT <<<\n","            if 0.90 <= best_conf <= 0.98 and best_breed == true_breed:\n","                # Avoid filename conflicts\n","                dest_name = f\"{breed}_{demo_saved+1}_{int(best_conf*100)}pct{img_path.suffix}\"\n","                dest_path = demo_dir / dest_name\n","                shutil.copy(img_path, dest_path)\n","                print(f\"✅ Added: {dest_name} → {best_breed} ({best_conf:.2f})\")\n","                demo_saved += 1\n","                breed_count[breed] += 1\n","                if demo_saved >= 10:\n","                    break\n","        except Exception as e:\n","            print(f\"❌ Error processing {img_path}: {e}\")\n","            continue\n","\n","print(f\"\\n🎉 Demo set ready: {demo_saved} images in {demo_dir}\")\n","print(\"📊 Breed distribution:\")\n","for breed, count in breed_count.items():\n","    if count > 0:\n","        print(f\"  {breed}: {count} images\")"],"metadata":{"id":"nH1-G0WIjx6T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758363469945,"user_tz":-330,"elapsed":4932,"user":{"displayName":"Yon Row","userId":"08931847390759870653"}},"outputId":"97558a19-dee5-4676-f665-a92c5bf9f585"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 11 breeds: ['Nagpuri', 'Jaffrabadi Buffalo', 'Hallikar', 'Murrah', 'Sahiwal', 'Kankrej', 'Jersey', 'Gir', 'Ayrshire', 'Tharparkar', 'Brown_Swiss']\n","\n","🔍 Building diverse demo set (confidence 90-98%)...\n","✅ Added: Gir_1_92pct.jpg → Gir (0.92)\n","✅ Added: Jersey_2_96pct.jpg → Jersey (0.97)\n","✅ Added: Jaffrabadi Buffalo_3_90pct.jpg → Jaffrabadi Buffalo (0.90)\n","✅ Added: Gir_4_92pct.jpg → Gir (0.92)\n","✅ Added: Brown_Swiss_5_97pct.jpg → Brown_Swiss (0.98)\n","✅ Added: Tharparkar_6_97pct.jpg → Tharparkar (0.98)\n","✅ Added: Brown_Swiss_7_96pct.jpg → Brown_Swiss (0.97)\n","✅ Added: Hallikar_8_97pct.jpg → Hallikar (0.98)\n","✅ Added: Murrah_9_97pct.jpg → Murrah (0.97)\n","✅ Added: Jersey_10_97pct.jpg → Jersey (0.98)\n","\n","🎉 Demo set ready: 10 images in /content/demo_images\n","📊 Breed distribution:\n","  Jaffrabadi Buffalo: 1 images\n","  Hallikar: 1 images\n","  Murrah: 1 images\n","  Jersey: 2 images\n","  Gir: 2 images\n","  Tharparkar: 1 images\n","  Brown_Swiss: 2 images\n"]}]},{"cell_type":"code","source":["predict_and_auto_label(\"/content/demo_images/Kankrej_7_95pct.jpg\", 0.90)"],"metadata":{"id":"kppZXyFi8DJ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758362688418,"user_tz":-330,"elapsed":642,"user":{"displayName":"Yon Row","userId":"08931847390759870653"}},"outputId":"750a098b-9a3f-49bc-8d36-c6b76b4130d8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🔍 PRODUCTION MODE: Analyzing /content/demo_images/Kankrej_7_95pct.jpg\n"," TOP PREDICTION: Kankrej (0.9522)\n"," LAST KNOWN VAL ACCURACY: 94.52%\n","\n"," TOP 3 BREEDS:\n","  1. Kankrej (0.9522)\n","  2. Jersey (0.0337)\n","  3. Tharparkar (0.0120)\n","\n"," AUTO-LABELING (Confidence 0.9522 >= 0.9)\n"," Saved to: /content/unlabelled_images/Kankrej_7_95pct.jpg\n"," Added to /content/pseudo_labels.csv → Ready for next retraining!\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3648945213.py:590: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  df = pd.concat([df, new_df], ignore_index=True)\n"]},{"output_type":"execute_result","data":{"text/plain":["('Kankrej', 0.9521840214729309)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["retrain_with_new_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wI5gH0ANgpVH","executionInfo":{"status":"ok","timestamp":1758288746816,"user_tz":-330,"elapsed":16373,"user":{"displayName":"Rakesh Mishra","userId":"09750190647182013057"}},"outputId":"4a56b650-41d3-4b1e-8a1f-1f3ee985a649"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🔄 Checking for pseudo-labels...\n","📥 Found 47 pseudo/human labels — starting retraining...\n","\n","+++ 🐄 Pseudo Epoch 1/5 +++\n","📈 Merged Loss: 0.2909\n","\n","+++ 🐄 Pseudo Epoch 2/5 +++\n","📈 Merged Loss: 0.3554\n","\n","+++ 🐄 Pseudo Epoch 3/5 +++\n","📈 Merged Loss: 0.2782\n","\n","+++ 🐄 Pseudo Epoch 4/5 +++\n","📈 Merged Loss: 0.2073\n","\n","+++ 🐄 Pseudo Epoch 5/5 +++\n","📈 Merged Loss: 0.2281\n","✅ Pseudo-training finished – model saved\n","\n","+++ 🐄 Pseudo Epoch 1/5 +++\n","📈 Merged Loss: 0.2398\n","\n","+++ 🐄 Pseudo Epoch 2/5 +++\n","📈 Merged Loss: 0.1683\n","\n","+++ 🐄 Pseudo Epoch 3/5 +++\n","📈 Merged Loss: 0.1603\n","\n","+++ 🐄 Pseudo Epoch 4/5 +++\n","📈 Merged Loss: 0.1430\n","\n","+++ 🐄 Pseudo Epoch 5/5 +++\n","📈 Merged Loss: 0.1872\n","✅ Pseudo-training finished – model saved\n"]}]},{"cell_type":"code","source":["!ls -l \"/content/Dataset2/Train\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LShNPcn8P509","executionInfo":{"status":"ok","timestamp":1757733704338,"user_tz":-330,"elapsed":125,"user":{"displayName":"Rakesh MISHRA","userId":"17957420342450672327"}},"outputId":"94b4c06f-7c9f-4c1e-b30f-a52ac7506b1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access '/content/Dataset2/Train': No such file or directory\n"]}]},{"cell_type":"code","source":["import os\n","\n","for breed in os.listdir(\"/content/Dataset3/Train\"):\n","    count = len(os.listdir(f\"/content/Dataset3/Train/{breed}\"))\n","    print(f\"train/{breed}: {count} images\")\n","\n","print(\"\\n---\")\n","\n","for breed in os.listdir(\"/content/Dataset3/Val\"):\n","    count = len(os.listdir(f\"/content/Dataset3/Val/{breed}\"))\n","    print(f\"val/{breed}: {count} images\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Y1P2BhFRILN","executionInfo":{"status":"ok","timestamp":1757669581292,"user_tz":-330,"elapsed":485,"user":{"displayName":"Rakesh MISHRA","userId":"17957420342450672327"}},"outputId":"8db3873b-9ce4-44e0-d7f6-b01b85e397bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train/Alambadi: 76 images\n","train/Bargur: 74 images\n","train/Banni: 86 images\n","train/Ayrshire: 184 images\n","train/Amritmahal: 75 images\n","\n","---\n","val/Alambadi: 20 images\n","val/Bargur: 19 images\n","val/Banni: 22 images\n","val/Ayrshire: 47 images\n","val/Amritmahal: 19 images\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"o7OHJrv68GE7"}},{"cell_type":"code","source":["!rm \"/content/Dataset3.zip\""],"metadata":{"id":"FBu3CGtxRIOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","EfficientNet-B0 – 85 %+ val, high-confidence, calibrated\n","- Soft-labels ready for pseudo-labelling\n","- Temperature scaling inside TTA\n","\"\"\"\n","import os, json, time, torch, torchvision, numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, models\n","import torchvision.transforms as T\n","from PIL import Image\n","from torch.cuda.amp import autocast, GradScaler\n","from timm.data.auto_augment import rand_augment_transform\n","from timm.data.mixup import Mixup\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using {device}\")\n","\n","# ---------- paths ----------\n","train_dir   = \"/content/New_data_train_val/train\"\n","val_dir     = \"/content/New_data_train_val/val\"\n","SAVE_BEST   = \"/content/best_model.pth\"\n","SAVE_FINAL  = \"/content/breed_model_efficientnet_finetuned.pth\"\n","SAVE_LABELS = \"/content/breed_names.json\"\n","TEST_IMAGE  = \"/content/New_data_train_val/val/Gir/Gir_168.jpg\"\n","\n","mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n","\n","# ---------- augmentation ----------\n","rand_aug = rand_augment_transform('rand-m7-mstd0.5', {})\n","train_tf = T.Compose([T.Resize((224, 224)), rand_aug, T.ToTensor(), T.Normalize(mean, std)])\n","\n","# ---------- test-time 10-crop ----------\n","val_tf = T.Compose([\n","    T.Resize(342),\n","    T.FiveCrop(256),\n","    T.Lambda(lambda crops: torch.stack([T.ToTensor()(c) for c in crops])),  # 5×3×256×256\n","    T.Normalize(mean, std)\n","])\n","\n","# ---------- datasets ----------\n","train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n","val_ds   = datasets.ImageFolder(val_dir,   transform=val_tf)\n","breed_names = train_ds.classes\n","\n","train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=2, pin_memory=True)\n","\n","# ---------- milder mix-up ----------\n","mixup_fn = Mixup(mixup_alpha=0.1, cutmix_alpha=0.2, prob=1.0,\n","                 num_classes=len(breed_names), label_smoothing=0.05)\n","\n","# ---------- model ----------\n","class Head(nn.Module):\n","    def __init__(self, in_features, n_classes, drop=0.2):\n","        super().__init__()\n","        self.drop = nn.Dropout(drop)\n","        self.fc   = nn.Linear(in_features, n_classes)\n","    def forward(self, x):\n","        return self.fc(self.drop(x))\n","\n","model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n","model.classifier = Head(model.classifier[1].in_features, len(breed_names))\n","model = model.to(device)\n","\n","# ---------- freeze ----------\n","for p in model.parameters(): p.requires_grad = False\n","for p in model.classifier.parameters(): p.requires_grad = True\n","\n","# ---------- class weights (used only first 10 epochs) ----------\n","labels = train_ds.targets\n","weights = torch.tensor(\n","    compute_class_weight('balanced', classes=np.arange(len(breed_names)), y=labels),\n","    dtype=torch.float, device=device)\n","\n","# ---------- optim ----------\n","optimizer = optim.AdamW(model.classifier.parameters(), lr=3e-3, weight_decay=5e-3)\n","scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","                optimizer, T_0=len(train_loader)*5, T_mult=1, eta_min=1e-6)\n","scaler = GradScaler()\n","\n","# ---------- helpers ----------\n","def unfreeze_and_add(stage, lr):\n","    frozen = []\n","    for name, module in model.features.named_children():\n","        if int(name) >= stage:\n","            for p in module.parameters():\n","                if not p.requires_grad:\n","                    p.requires_grad = True\n","                    frozen.append(p)\n","    if frozen:\n","        optimizer.add_param_group({'params': frozen, 'lr': lr})\n","\n","# ---------- metrics ----------\n","best_val_loss = 1e9\n","patience = 15\n","pat_counter = 0\n","accum = 2\n","grad_clip = 1.0\n","TEMP = 1.5  # temperature for calibration (tuned on val)\n","\n","# ---------- train ----------\n","for epoch in range(30):\n","    print(f\"\\n----- epoch {epoch+1}/30 -----\")\n","    # ---- unfreeze ----\n","    if epoch == 3: unfreeze_and_add(6, 3e-4)\n","    if epoch == 6: unfreeze_and_add(4, 1e-4)\n","    if epoch == 9: unfreeze_and_add(0, 5e-5)\n","\n","    # ---- loss choice ----\n","    criterion = nn.CrossEntropyLoss(weight=weights if epoch < 10 else None, label_smoothing=0.05)\n","\n","    # ---- train ----\n","    model.train()\n","    running = 0.\n","    for i, (x, y) in enumerate(train_loader):\n","        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n","        x, y = mixup_fn(x, y)\n","        with autocast():\n","            out = model(x)\n","            loss = criterion(out, y) / accum\n","        scaler.scale(loss).backward()\n","        if (i+1) % accum == 0 or i+1 == len(train_loader):\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","            scaler.step(optimizer); scaler.update(); optimizer.zero_grad(set_to_none=True)\n","        running += loss.item() * accum\n","    print(f\"train loss {running/len(train_loader):.4f}\")\n","\n","    # ---- validate (10-crop) ----\n","    model.eval()\n","    val_loss, correct, total = 0., 0, 0\n","    with torch.no_grad():\n","        for x, y in val_loader:\n","            B = y.size(0)\n","            x = x.view(-1, 3, 256, 256).to(device)  # 5*crops\n","            y = y.to(device)\n","            with autocast():\n","                out = model(x) / TEMP               # temperature scaling\n","                out = out.view(5, B, -1).mean(0)    # 5-crop average\n","                val_loss += criterion(out, y).item()\n","            # horizontal-flip TTA\n","            out_flip = model(torch.flip(x, dims=[-1])) / TEMP\n","            out_flip = out_flip.view(5, B, -1).mean(0)\n","            out = (out + out_flip) / 2\n","            pred = out.argmax(1)\n","            correct += (pred == y).sum().item()\n","            total += B\n","    val_loss /= len(val_loader)\n","    val_acc = 100 * correct / total\n","    print(f\"val_loss {val_loss:.4f}  val_acc {val_acc:.2f}%\")\n","\n","    # ---- early stop ----\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), SAVE_BEST)\n","        pat_counter = 0\n","    else:\n","        pat_counter += 1\n","        if pat_counter >= patience:\n","            print(\"early stop\"); break\n","    scheduler.step()\n","\n","# ---------- save ----------\n","model.load_state_dict(torch.load(SAVE_BEST))\n","torch.save(model, SAVE_FINAL)\n","with open(SAVE_LABELS, \"w\") as f:\n","    json.dump(breed_names, f)\n","print(\"Saved best model & labels\")\n","\n","# ---------- high-confidence TTA ----------\n","def tta_predict(image_path, temp=TEMP):\n","    model.eval()\n","    img = Image.open(image_path).convert('RGB')\n","    crops = val_tf(img).to(device)          # 5×3×256×256\n","    with torch.no_grad():\n","        with autocast():\n","            logits = model(crops) / temp    # temperature\n","            prob = torch.softmax(logits, dim=1).mean(0)\n","            # flip\n","            logits_flip = model(torch.flip(crops, dims=[-1])) / temp\n","            prob_flip = torch.softmax(logits_flip, dim=1).mean(0)\n","            prob = (prob + prob_flip) / 2\n","    conf, pred = prob.max(0)\n","    return breed_names[pred.item()], conf.item()\n","\n","if os.path.exists(TEST_IMAGE):\n","    breed, conf = tta_predict(TEST_IMAGE)\n","    print(f\"TTA pred: {breed}  (confidence {conf:.4f})\")\n","else:\n","    print(\"Test image not found\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjWKvy-wRIQF","executionInfo":{"status":"ok","timestamp":1757957357555,"user_tz":-330,"elapsed":527299,"user":{"displayName":"Rakesh MISHRA","userId":"17957420342450672327"}},"outputId":"1b14c7f8-4baa-45f5-9fc1-51ddae906ff3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda\n","\n","----- epoch 1/30 -----\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1284013260.py:82: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","/tmp/ipython-input-1284013260.py:121: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():\n"]},{"output_type":"stream","name":"stdout","text":["train loss 2.2250\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1284013260.py:140: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():\n"]},{"output_type":"stream","name":"stdout","text":["val_loss 1.8380  val_acc 65.04%\n","\n","----- epoch 2/30 -----\n","train loss 1.8831\n","val_loss 1.7479  val_acc 61.02%\n","\n","----- epoch 3/30 -----\n","train loss 1.8314\n","val_loss 1.7150  val_acc 72.25%\n","\n","----- epoch 4/30 -----\n","train loss 1.8613\n","val_loss 1.5529  val_acc 73.52%\n","\n","----- epoch 5/30 -----\n","train loss 1.6910\n","val_loss 1.4759  val_acc 76.27%\n","\n","----- epoch 6/30 -----\n","train loss 1.5096\n","val_loss 1.4303  val_acc 81.14%\n","\n","----- epoch 7/30 -----\n","train loss 1.4599\n","val_loss 1.4516  val_acc 76.91%\n","\n","----- epoch 8/30 -----\n","train loss 1.4490\n","val_loss 1.4831  val_acc 75.42%\n","\n","----- epoch 9/30 -----\n","train loss 1.3494\n","val_loss 1.4673  val_acc 72.25%\n","\n","----- epoch 10/30 -----\n","train loss 1.4370\n","val_loss 1.4533  val_acc 77.75%\n","\n","----- epoch 11/30 -----\n","train loss 1.2593\n","val_loss 1.3173  val_acc 83.69%\n","\n","----- epoch 12/30 -----\n","train loss 1.3305\n","val_loss 1.3257  val_acc 80.93%\n","\n","----- epoch 13/30 -----\n","train loss 1.3175\n","val_loss 1.3386  val_acc 81.14%\n","\n","----- epoch 14/30 -----\n","train loss 1.3199\n","val_loss 1.3327  val_acc 85.17%\n","\n","----- epoch 15/30 -----\n","train loss 1.2083\n","val_loss 1.3310  val_acc 83.69%\n","\n","----- epoch 16/30 -----\n","train loss 1.2122\n","val_loss 1.3324  val_acc 82.42%\n","\n","----- epoch 17/30 -----\n","train loss 1.2704\n","val_loss 1.3489  val_acc 81.99%\n","\n","----- epoch 18/30 -----\n","train loss 1.2089\n","val_loss 1.3615  val_acc 80.51%\n","\n","----- epoch 19/30 -----\n","train loss 1.1584\n","val_loss 1.3514  val_acc 80.93%\n","\n","----- epoch 20/30 -----\n","train loss 1.1855\n","val_loss 1.3338  val_acc 79.03%\n","\n","----- epoch 21/30 -----\n","train loss 1.1025\n","val_loss 1.3367  val_acc 81.99%\n","\n","----- epoch 22/30 -----\n","train loss 1.1675\n","val_loss 1.3764  val_acc 80.51%\n","\n","----- epoch 23/30 -----\n","train loss 1.1509\n","val_loss 1.3195  val_acc 80.30%\n","\n","----- epoch 24/30 -----\n","train loss 1.0968\n","val_loss 1.3508  val_acc 81.57%\n","\n","----- epoch 25/30 -----\n","train loss 1.0559\n","val_loss 1.3357  val_acc 82.63%\n","\n","----- epoch 26/30 -----\n","train loss 1.0317\n","val_loss 1.3314  val_acc 83.90%\n","early stop\n","Saved best model & labels\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1284013260.py:179: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():\n"]},{"output_type":"stream","name":"stdout","text":["TTA pred: Gir  (confidence 0.7002)\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"mP9ybM998XNy"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"-51Tci0S33BX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758352993101,"user_tz":-330,"elapsed":94860,"user":{"displayName":"Yon Row","userId":"08931847390759870653"}},"outputId":"88374eb2-b40b-4b09-9ca0-2c2a8130b1f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os, json, time, torch, torchvision, numpy as np, shutil, pandas as pd\n","from pathlib import Path\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import datasets, models\n","import torchvision.transforms as T\n","from PIL import Image\n","from torch.amp import autocast, GradScaler\n","from timm.data.auto_augment import rand_augment_transform\n","from timm.data.mixup import Mixup\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"🚀 Using {device}\")\n","\n","# ---------- CONFIG ----------\n","train_dir      = \"/content/drive/MyDrive/New_data_train_val/train\"\n","val_dir        = \"/content/drive/MyDrive/New_data_train_val/val\"\n","UNLABELLED_DIR = \"/content/unlabelled_images\"\n","PSEUDO_CSV     = \"/content/pseudo_labels.csv\"\n","SAVE_BEST      = \"/content/best_model.pth\"\n","SAVE_FINAL     = \"/content/breed_model_efficientnet_finetuned.pth\"\n","SAVE_LABELS    = \"/content/breed_names.json\"\n","TEST_IMAGE     = \"/content/drive/MyDrive/New_data_train_val/val/Kankrej/Kankrej_140.jpg\"\n","\n","SOFT_THR       = 0.90\n","TEMP           = 1.2\n","RETRAIN_EPOCHS = 5\n","mean, std      = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n","\n","# ---------- transforms ----------\n","rand_aug = rand_augment_transform('rand-m7-mstd0.5', {})\n","train_tf = T.Compose([T.Resize((224, 224)), rand_aug, T.ToTensor(), T.Normalize(mean, std)])\n","unlabelled_tf = T.Compose([\n","    T.Resize(342), T.FiveCrop(256),\n","    T.Lambda(lambda crops: torch.stack([T.ToTensor()(c) for c in crops])),\n","    T.Normalize(mean, std)\n","])\n","val_tf = T.Compose([\n","    T.Resize(342), T.FiveCrop(256),\n","    T.Lambda(lambda crops: torch.stack([T.ToTensor()(c) for c in crops])),\n","    T.Normalize(mean, std)\n","])\n","\n","# ---------- datasets ----------\n","train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n","val_ds   = datasets.ImageFolder(val_dir,   transform=val_tf)\n","breed_names = train_ds.classes\n","train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=2, pin_memory=True)\n","\n","# ---------- mixup ----------\n","mixup_fn = Mixup(mixup_alpha=0.1, cutmix_alpha=0.2, prob=1.0,\n","                 num_classes=len(breed_names), label_smoothing=0.05)\n","\n","# ---------- model ----------\n","class Head(nn.Module):\n","    def __init__(self, in_features, n_classes, drop=0.2):\n","        super().__init__()\n","        self.drop = nn.Dropout(drop)\n","        self.fc   = nn.Linear(in_features, n_classes)\n","    def forward(self, x):\n","        return self.fc(self.drop(x))\n","\n","model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n","model.classifier = Head(model.classifier[1].in_features, len(breed_names))\n","model = model.to(device)\n","\n","# ---------- freeze ----------\n","for p in model.parameters(): p.requires_grad = False\n","for p in model.classifier.parameters(): p.requires_grad = True\n","\n","# ---------- class weights ----------\n","labels = train_ds.targets\n","weights = torch.tensor(\n","    compute_class_weight('balanced', classes=np.arange(len(breed_names)), y=labels),\n","    dtype=torch.float, device=device)\n","\n","# ---------- optim ----------\n","optimizer = optim.AdamW(model.classifier.parameters(), lr=3e-3, weight_decay=5e-3)\n","scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","                optimizer, T_0=len(train_loader)*5, T_mult=1, eta_min=1e-6)\n","scaler = GradScaler('cuda')\n","\n","# ---------- helpers ----------\n","def unfreeze_and_add(stage, lr):\n","    frozen = []\n","    for name, module in model.features.named_children():\n","        if int(name) >= stage:\n","            for p in module.parameters():\n","                if not p.requires_grad:\n","                    p.requires_grad = True\n","                    frozen.append(p)\n","    if frozen:\n","        optimizer.add_param_group({'params': frozen, 'lr': lr})\n","\n","# ---------- global metrics ----------\n","best_val_loss = 1e9\n","patience = 15\n","pat_counter = 0\n","accum = 2\n","grad_clip = 1.0\n","TEMP = 1.2\n","\n","# ===================================================================\n","#  1. MAIN TRAINING\n","# ===================================================================\n","def main_training():\n","    global best_val_loss, pat_counter\n","    for epoch in range(30):\n","        print(f\"\\n----- 🐄 Epoch {epoch+1}/30 -----\")\n","        if epoch == 3: unfreeze_and_add(6, 3e-4)\n","        if epoch == 6: unfreeze_and_add(4, 1e-4)\n","        if epoch == 9: unfreeze_and_add(0, 5e-5)\n","\n","        criterion = nn.CrossEntropyLoss(weight=weights if epoch < 10 else None, label_smoothing=0.05)\n","\n","        model.train()\n","        running = 0.\n","        for i, (x, y) in enumerate(train_loader):\n","            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n","            x, y = mixup_fn(x, y)\n","            with autocast('cuda'):\n","                out = model(x)\n","                loss = criterion(out, y) / accum\n","            scaler.scale(loss).backward()\n","            if (i+1) % accum == 0 or i+1 == len(train_loader):\n","                scaler.unscale_(optimizer)\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","                scaler.step(optimizer); scaler.update(); optimizer.zero_grad(set_to_none=True)\n","            running += loss.item() * accum\n","        print(f\"📈 Train Loss: {running/len(train_loader):.4f}\")\n","\n","        # ---- validate ----\n","        model.eval()\n","        val_loss, correct, total = 0., 0, 0\n","        with torch.no_grad():\n","            for x, y in val_loader:\n","                B = y.size(0)\n","                x = x.view(-1, 3, 256, 256).to(device)\n","                y = y.to(device)\n","                with autocast('cuda'):\n","                    out = model(x) / TEMP\n","                    out = out.view(5, B, -1).mean(0)\n","                    out_flip = model(torch.flip(x, dims=[-1])) / TEMP\n","                    out_flip = out_flip.view(5, B, -1).mean(0)\n","                    out = (out + out_flip) / 2\n","                    val_loss += nn.CrossEntropyLoss()(out, y).item()\n","                pred = out.argmax(1)\n","                correct += (pred == y).sum().item()\n","                total += B\n","        val_loss /= len(val_loader)\n","        val_acc = 100 * correct / total\n","        print(f\"🎯 Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), SAVE_BEST)\n","            pat_counter = 0\n","            print(f\"⭐ New best model saved (val_loss={val_loss:.4f})\")\n","        else:\n","            pat_counter += 1\n","            if pat_counter >= patience:\n","                print(\"🛑 Early stopping triggered\")\n","                break\n","        scheduler.step()\n","\n","    model.load_state_dict(torch.load(SAVE_BEST))\n","    torch.save(model, SAVE_FINAL)\n","    with open(SAVE_LABELS, \"w\") as f:\n","        json.dump(breed_names, f)\n","    print(\"✅ Main training finished – best model saved\")\n","\n","# ===================================================================\n","#  2. PSEUDO + HUMAN-IN-THE-LOOP\n","# ===================================================================\n","def predict_image(image_path, temp=TEMP):\n","    model.eval()\n","    img = Image.open(image_path).convert('RGB')\n","    crops = unlabelled_tf(img).to(device)\n","    with torch.no_grad():\n","        with autocast('cuda'):\n","            logits = model(crops) / temp\n","            prob = torch.softmax(logits, dim=1).mean(0)\n","            logits_flip = model(torch.flip(crops, dims=[-1])) / temp\n","            prob_flip = torch.softmax(logits_flip, dim=1).mean(0)\n","            prob = (prob + prob_flip) / 2\n","    top3 = torch.topk(prob, k=3)\n","    return [(breed_names[i], float(p)) for i, p in zip(top3.indices, top3.values)], prob.cpu()\n","\n","def worker_choice(image_path, top3):\n","    print(f\"\\n📸 Image: {image_path}\")\n","    for idx, (b, p) in enumerate(top3, 1):\n","        print(f\"  {idx}. {b}  ({p*100:.1f}%)\")\n","    while True:\n","        try:\n","            choice = input(\"👉 Choose 1-3 (or 0 to skip): \").strip()\n","            if choice == \"0\":\n","                return None\n","            choice = int(choice)\n","            if 1 <= choice <= 3:\n","                return top3[choice-1][0]\n","            else:\n","                print(\"⚠️ Please enter 0, 1, 2, or 3.\")\n","        except ValueError:\n","            print(\"⚠️ Invalid input – please enter a number.\")\n","\n","def create_pseudo_csv():\n","    unlabelled_path = Path(UNLABELLED_DIR)\n","    if not unlabelled_path.exists():\n","        print(f\"❌ Unlabelled directory not found: {UNLABELLED_DIR}\")\n","        pd.DataFrame(columns=['file', 'label', 'confidence', 'type']).to_csv(PSEUDO_CSV, index=False)\n","        return pd.DataFrame()\n","\n","    # Find image files\n","    image_files = list(unlabelled_path.rglob(\"*.[jJ][pP][gG]\")) + \\\n","                  list(unlabelled_path.rglob(\"*.[jJ][pP][eE][gG]\")) + \\\n","                  list(unlabelled_path.rglob(\"*.[pP][nN][gG]\"))\n","\n","    if len(image_files) == 0:\n","        print(f\"⚠️ No images found in {UNLABELLED_DIR}\")\n","        pd.DataFrame(columns=['file', 'label', 'confidence', 'type']).to_csv(PSEUDO_CSV, index=False)\n","        return pd.DataFrame()\n","\n","    print(f\"🔍 Found {len(image_files)} images to label...\")\n","    records = []\n","\n","    for img_path in image_files:\n","        try:\n","            top3, soft_prob = predict_image(img_path)\n","            best_breed, best_conf = top3[0]\n","\n","            if best_conf >= SOFT_THR:\n","                records.append({\n","                    'file': str(img_path),\n","                    'label': best_breed,\n","                    'confidence': best_conf,\n","                    'type': 'pseudo'\n","                })\n","                print(f\"🤖 Auto-labeled: {img_path.name} → {best_breed} ({best_conf:.2f})\")\n","            else:\n","                chosen = worker_choice(img_path, top3)\n","                if chosen is not None:\n","                    records.append({\n","                        'file': str(img_path),\n","                        'label': chosen,\n","                        'confidence': 1.0,\n","                        'type': 'human'\n","                    })\n","                    print(f\"👩‍🌾 Human-labeled: {img_path.name} → {chosen}\")\n","                else:\n","                    print(f\"⏭️ Skipped: {img_path.name}\")\n","\n","        except Exception as e:\n","            print(f\"❌ Error processing {img_path}: {e}\")\n","            continue\n","\n","    df = pd.DataFrame(records)\n","    df.to_csv(PSEUDO_CSV, index=False)\n","    print(f\"✅ CSV saved → {len(df)} new labels collected\")\n","    return df\n","\n","# ===================================================================\n","#  3. SOFT-HARD DATASET + RETRAIN\n","# ===================================================================\n","class SoftHardDataset(Dataset):\n","    def __init__(self, csv_file, root, transform, class_to_idx):\n","        if not os.path.exists(csv_file):\n","            self.samples = []\n","            return\n","        try:\n","            self.df = pd.read_csv(csv_file)\n","        except pd.errors.EmptyDataError:\n","            self.df = pd.DataFrame()\n","        self.root = root\n","        self.transform = transform\n","        self.class_to_idx = class_to_idx\n","        self.samples = []\n","        if len(self.df) > 0:\n","            for _, row in self.df.iterrows():\n","                self.samples.append((row['file'], row['label'], row['confidence'], row['type']))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        path, label, conf, typ = self.samples[idx]\n","        img = Image.open(path).convert('RGB')\n","        if self.transform:\n","            img = self.transform(img)\n","        if typ == 'pseudo':\n","            target = torch.zeros(len(self.class_to_idx))\n","            target[self.class_to_idx[label]] = conf\n","            return img, target.float()\n","        else:\n","            return img, self.class_to_idx[label]\n","\n","def retrain_with_new_data(extra_epochs=RETRAIN_EPOCHS):\n","    global accum, grad_clip\n","\n","    print(\"\\n🔄 Checking for pseudo-labels...\")\n","\n","    # Safety check: if CSV doesn't exist or is empty, skip\n","    if not os.path.exists(PSEUDO_CSV):\n","        print(\"⚠️ Pseudo-labels CSV not found — skipping retraining.\")\n","        return\n","\n","    try:\n","        df = pd.read_csv(PSEUDO_CSV)\n","    except pd.errors.EmptyDataError:\n","        print(\"⚠️ Pseudo-labels CSV is empty — skipping retraining.\")\n","        return\n","\n","    if len(df) == 0:\n","        print(\"⚠️ No pseudo-labels collected — skipping retraining.\")\n","        return\n","\n","    print(f\"📥 Found {len(df)} pseudo/human labels — starting retraining...\")\n","\n","    merged_root = \"/content/merged_train\"\n","    os.makedirs(merged_root, exist_ok=True)\n","\n","    # Copy original training data\n","    os.system(f\"cp -r {train_dir}/* {merged_root}/ 2>/dev/null || echo 'Original data copied'\")\n","\n","    # Copy pseudo-labeled images into breed folders\n","    for _, row in df.iterrows():\n","        src = Path(row['file'])\n","        breed = row['label']\n","        breed_dir = Path(merged_root) / breed\n","        breed_dir.mkdir(exist_ok=True)\n","        dst = breed_dir / src.name\n","        if not dst.exists():\n","            shutil.copy(src, dst)\n","\n","    # Create dataset and loader\n","    merged_ds = SoftHardDataset(PSEUDO_CSV, merged_root, transform=train_tf,\n","                                class_to_idx=train_ds.class_to_idx)\n","    if len(merged_ds) == 0:\n","        print(\"⚠️ Merged dataset is empty — skipping retraining.\")\n","        return\n","\n","    merged_loader = DataLoader(merged_ds, batch_size=16, shuffle=True,\n","                               num_workers=2, pin_memory=True)\n","\n","    # Add all parameters to optimizer (for fine-tuning)\n","    optimizer.add_param_group({'params': model.parameters(), 'lr': 1e-4})\n","    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","                    optimizer, T_0=len(merged_loader)*3, T_mult=1, eta_min=1e-6)\n","\n","    # Custom criterion for soft/hard labels\n","    def criterion(out, y):\n","        if y.dtype is torch.float32:\n","            return -torch.sum(y * torch.log_softmax(out, dim=1), dim=1).mean()\n","        else:\n","            return nn.CrossEntropyLoss()(out, y)\n","\n","    # Retrain loop\n","    for epoch in range(extra_epochs):\n","        print(f\"\\n+++ 🐄 Pseudo Epoch {epoch+1}/{extra_epochs} +++\")\n","        model.train()\n","        running = 0.\n","        for x, y in merged_loader:\n","            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n","            with autocast('cuda'):\n","                out = model(x)\n","                loss = criterion(out, y) / accum\n","            scaler.scale(loss).backward()\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","            scaler.step(optimizer); scaler.update(); optimizer.zero_grad(set_to_none=True)\n","            running += loss.item() * accum\n","        print(f\"📈 Merged Loss: {running/len(merged_loader):.4f}\")\n","\n","    torch.save(model, \"/content/model_after_pseudo.pth\")\n","    print(\"✅ Pseudo-training finished – model saved\")\n","\n","# ===================================================================\n","#  4. RUN PIPELINE\n","# ===================================================================\n","if __name__ == \"__main__\":\n","    print(\"🏁 Starting full training pipeline...\")\n","    main_training()               # 1. Train on original data\n","    df = create_pseudo_csv()      # 2. Collect pseudo + human labels\n","    if len(df) > 0:\n","        retrain_with_new_data()   # 3. Retrain on merged set (only if we have labels)\n","    else:\n","        print(\"⏭️ Skipping retraining — no new labels collected.\")\n","\n","    print(\"\\n🎉 PIPELINE COMPLETE!\")\n","    print(\"💾 Final model: /content/breed_model_efficientnet_finetuned.pth\")\n","    print(\"🏷️  Breed names: /content/breed_names.json\")\n","    if os.path.exists(\"/content/model_after_pseudo.pth\"):\n","        print(\"🆙 Upgraded model: /content/model_after_pseudo.pth\")"],"metadata":{"id":"LVyBoarfESkw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"409cf157-bc3c-4ad6-8930-6dd182d14e06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Using cuda\n","🏁 Starting full training pipeline...\n","\n","----- 🐄 Epoch 1/30 -----\n","📈 Train Loss: 2.1795\n","🎯 Val Loss: 1.6187 | Val Acc: 65.04%\n","⭐ New best model saved (val_loss=1.6187)\n","\n","----- 🐄 Epoch 2/30 -----\n","📈 Train Loss: 1.8951\n","🎯 Val Loss: 1.4817 | Val Acc: 71.19%\n","⭐ New best model saved (val_loss=1.4817)\n","\n","----- 🐄 Epoch 3/30 -----\n","📈 Train Loss: 1.8830\n","🎯 Val Loss: 1.4689 | Val Acc: 72.03%\n","⭐ New best model saved (val_loss=1.4689)\n","\n","----- 🐄 Epoch 4/30 -----\n","📈 Train Loss: 1.7931\n","🎯 Val Loss: 1.3077 | Val Acc: 72.67%\n","⭐ New best model saved (val_loss=1.3077)\n","\n","----- 🐄 Epoch 5/30 -----\n","📈 Train Loss: 1.6161\n","🎯 Val Loss: 1.2741 | Val Acc: 69.49%\n","⭐ New best model saved (val_loss=1.2741)\n","\n","----- 🐄 Epoch 6/30 -----\n","📈 Train Loss: 1.5991\n","🎯 Val Loss: 1.1045 | Val Acc: 77.12%\n","⭐ New best model saved (val_loss=1.1045)\n","\n","----- 🐄 Epoch 7/30 -----\n","📈 Train Loss: 1.6156\n","🎯 Val Loss: 1.1997 | Val Acc: 74.79%\n","\n","----- 🐄 Epoch 8/30 -----\n","📈 Train Loss: 1.4182\n","🎯 Val Loss: 1.0791 | Val Acc: 78.60%\n","⭐ New best model saved (val_loss=1.0791)\n","\n","----- 🐄 Epoch 9/30 -----\n","📈 Train Loss: 1.4256\n","🎯 Val Loss: 1.0961 | Val Acc: 78.39%\n","\n","----- 🐄 Epoch 10/30 -----\n","📈 Train Loss: 1.3725\n","🎯 Val Loss: 1.1181 | Val Acc: 81.14%\n","\n","----- 🐄 Epoch 11/30 -----\n","📈 Train Loss: 1.2939\n","🎯 Val Loss: 1.0283 | Val Acc: 85.38%\n","⭐ New best model saved (val_loss=1.0283)\n","\n","----- 🐄 Epoch 12/30 -----\n","📈 Train Loss: 1.2702\n","🎯 Val Loss: 1.0461 | Val Acc: 81.57%\n","\n","----- 🐄 Epoch 13/30 -----\n","📈 Train Loss: 1.2415\n","🎯 Val Loss: 1.0417 | Val Acc: 81.78%\n","\n","----- 🐄 Epoch 14/30 -----\n","📈 Train Loss: 1.2100\n","🎯 Val Loss: 1.0175 | Val Acc: 79.03%\n","⭐ New best model saved (val_loss=1.0175)\n","\n","----- 🐄 Epoch 15/30 -----\n","📈 Train Loss: 1.2151\n","🎯 Val Loss: 1.1057 | Val Acc: 76.91%\n","\n","----- 🐄 Epoch 16/30 -----\n","📈 Train Loss: 1.2621\n","🎯 Val Loss: 1.1060 | Val Acc: 82.42%\n","\n","----- 🐄 Epoch 17/30 -----\n","📈 Train Loss: 1.2090\n","🎯 Val Loss: 1.0929 | Val Acc: 84.11%\n","\n","----- 🐄 Epoch 18/30 -----\n","📈 Train Loss: 1.1965\n","🎯 Val Loss: 1.0366 | Val Acc: 81.57%\n","\n","----- 🐄 Epoch 19/30 -----\n","📈 Train Loss: 1.1892\n","🎯 Val Loss: 1.0802 | Val Acc: 82.20%\n","\n","----- 🐄 Epoch 20/30 -----\n","📈 Train Loss: 1.2088\n","🎯 Val Loss: 1.0361 | Val Acc: 81.36%\n","\n","----- 🐄 Epoch 21/30 -----\n","📈 Train Loss: 1.2102\n","🎯 Val Loss: 1.0229 | Val Acc: 80.30%\n","\n","----- 🐄 Epoch 22/30 -----\n","📈 Train Loss: 1.1068\n","🎯 Val Loss: 1.0871 | Val Acc: 80.51%\n","\n","----- 🐄 Epoch 23/30 -----\n","📈 Train Loss: 1.2059\n","🎯 Val Loss: 1.1736 | Val Acc: 80.72%\n","\n","----- 🐄 Epoch 24/30 -----\n","📈 Train Loss: 1.2225\n","🎯 Val Loss: 1.0970 | Val Acc: 80.93%\n","\n","----- 🐄 Epoch 25/30 -----\n","📈 Train Loss: 1.2508\n","🎯 Val Loss: 1.1437 | Val Acc: 81.78%\n","\n","----- 🐄 Epoch 26/30 -----\n","📈 Train Loss: 1.0762\n","🎯 Val Loss: 1.0903 | Val Acc: 81.36%\n","\n","----- 🐄 Epoch 27/30 -----\n","📈 Train Loss: 1.1045\n"]}]},{"cell_type":"code","source":["# finall improved code by :- deepseek\n","import os, json, time, torch, torchvision, numpy as np, shutil, pandas as pd\n","from pathlib import Path\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import datasets, models\n","import torchvision.transforms as T\n","from PIL import Image\n","from torch.amp import autocast, GradScaler\n","from timm.data.auto_augment import rand_augment_transform\n","from timm.data.mixup import Mixup\n","from sklearn.utils.class_weight import compute_class_weight\n","import cv2\n","from datetime import datetime\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"🚀 Using {device}\")\n","\n","# ---------- CONFIG ----------\n","train_dir      = \"/content/drive/MyDrive/New_data_train_val/train\"\n","val_dir        = \"/content/drive/MyDrive/New_data_train_val/val\"\n","UNLABELLED_DIR = \"/content/unlabelled_images\"\n","PROCESSED_DIR = \"/content/processed_images\"  # To store images after processing\n","PSEUDO_CSV     = \"/content/pseudo_labels.csv\"\n","SAVE_BEST      = \"/content/best_model.pth\"\n","SAVE_FINAL     = \"/content/breed_model_efficientnet_finetuned.pth\"\n","SAVE_LABELS    = \"/content/breed_names.json\"\n","TEST_IMAGE     = \"/content/drive/MyDrive/New_data_train_val/val/Sahiwal/Sahiwal_155.jpg\"\n","\n","SOFT_THR       = 0.90  # Confidence threshold for auto-labeling\n","TEMP           = 1.2\n","RETRAIN_EPOCHS = 5\n","mean, std      = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n","\n","# Create directories if they don't exist\n","os.makedirs(UNLABELLED_DIR, exist_ok=True)\n","os.makedirs(PROCESSED_DIR, exist_ok=True)\n","\n","# ---------- transforms ----------\n","rand_aug = rand_augment_transform('rand-m7-mstd0.5', {})\n","train_tf = T.Compose([T.Resize((224, 224)), rand_aug, T.ToTensor(), T.Normalize(mean, std)])\n","unlabelled_tf = T.Compose([\n","    T.Resize(342), T.FiveCrop(256),\n","    T.Lambda(lambda crops: torch.stack([T.ToTensor()(c) for c in crops])),\n","    T.Normalize(mean, std)\n","])\n","val_tf = T.Compose([\n","    T.Resize(342), T.FiveCrop(256),\n","    T.Lambda(lambda crops: torch.stack([T.ToTensor()(c) for c in crops])),\n","    T.Normalize(mean, std)\n","])\n","\n","# ---------- datasets ----------\n","train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n","val_ds   = datasets.ImageFolder(val_dir,   transform=val_tf)\n","breed_names = train_ds.classes\n","train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=2, pin_memory=True)\n","\n","# ---------- mixup ----------\n","mixup_fn = Mixup(mixup_alpha=0.1, cutmix_alpha=0.2, prob=1.0,\n","                 num_classes=len(breed_names), label_smoothing=0.05)\n","\n","# ---------- model ----------\n","class Head(nn.Module):\n","    def __init__(self, in_features, n_classes, drop=0.2):\n","        super().__init__()\n","        self.drop = nn.Dropout(drop)\n","        self.fc   = nn.Linear(in_features, n_classes)\n","    def forward(self, x):\n","        return self.fc(self.drop(x))\n","\n","model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n","model.classifier = Head(model.classifier[1].in_features, len(breed_names))\n","model = model.to(device)\n","\n","# ---------- freeze ----------\n","for p in model.parameters(): p.requires_grad = False\n","for p in model.classifier.parameters(): p.requires_grad = True\n","\n","# ---------- class weights ----------\n","labels = train_ds.targets\n","weights = torch.tensor(\n","    compute_class_weight('balanced', classes=np.arange(len(breed_names)), y=labels),\n","    dtype=torch.float, device=device)\n","\n","# ---------- optim ----------\n","optimizer = optim.AdamW(model.classifier.parameters(), lr=3e-3, weight_decay=5e-3)\n","scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","                optimizer, T_0=len(train_loader)*5, T_mult=1, eta_min=1e-6)\n","scaler = GradScaler('cuda')\n","\n","# ---------- helpers ----------\n","def unfreeze_and_add(stage, lr):\n","    frozen = []\n","    for name, module in model.features.named_children():\n","        if int(name) >= stage:\n","            for p in module.parameters():\n","                if not p.requires_grad:\n","                    p.requires_grad = True\n","                    frozen.append(p)\n","    if frozen:\n","        optimizer.add_param_group({'params': frozen, 'lr': lr})\n","\n","# ---------- global metrics ----------\n","best_val_loss = 1e9\n","patience = 15\n","pat_counter = 0\n","accum = 2\n","grad_clip = 1.0\n","TEMP = 1.2\n","\n","# ===================================================================\n","#  CAPTURE/STORE IMAGES FROM FLWs\n","# ===================================================================\n","def capture_and_store_image(image_path=None, image_array=None, camera_index=0):\n","    \"\"\"\n","    Capture an image from camera or save provided image to unlabelled folder\n","    \"\"\"\n","    if image_path and os.path.exists(image_path):\n","        # Copy provided image to unlabelled folder\n","        filename = os.path.basename(image_path)\n","        dest_path = os.path.join(UNLABELLED_DIR, f\"{int(time.time())}_{filename}\")\n","        shutil.copy(image_path, dest_path)\n","        print(f\"📁 Image saved to {dest_path}\")\n","        return dest_path\n","    elif image_array is not None:\n","        # Save image array to unlabelled folder\n","        filename = f\"captured_{int(time.time())}.jpg\"\n","        dest_path = os.path.join(UNLABELLED_DIR, filename)\n","        cv2.imwrite(dest_path, image_array)\n","        print(f\"📁 Image saved to {dest_path}\")\n","        return dest_path\n","    else:\n","        # Capture from camera\n","        cap = cv2.VideoCapture(camera_index)\n","        ret, frame = cap.read()\n","        cap.release()\n","\n","        if ret:\n","            filename = f\"captured_{int(time.time())}.jpg\"\n","            dest_path = os.path.join(UNLABELLED_DIR, filename)\n","            cv2.imwrite(dest_path, frame)\n","            print(f\"📁 Image captured and saved to {dest_path}\")\n","            return dest_path\n","        else:\n","            print(\"❌ Failed to capture image from camera\")\n","            return None\n","\n","# ===================================================================\n","#  1. MAIN TRAINING\n","# ===================================================================\n","def main_training():\n","    global best_val_loss, pat_counter\n","    for epoch in range(30):\n","        print(f\"\\n----- 🐄 Epoch {epoch+1}/30 -----\")\n","        if epoch == 3: unfreeze_and_add(6, 3e-4)\n","        if epoch == 6: unfreeze_and_add(4, 1e-4)\n","        if epoch == 9: unfreeze_and_add(0, 5e-5)\n","\n","        criterion = nn.CrossEntropyLoss(weight=weights if epoch < 10 else None, label_smoothing=0.05)\n","\n","        model.train()\n","        running = 0.\n","        for i, (x, y) in enumerate(train_loader):\n","            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n","            x, y = mixup_fn(x, y)\n","            with autocast('cuda'):\n","                out = model(x)\n","                loss = criterion(out, y) / accum\n","            scaler.scale(loss).backward()\n","            if (i+1) % accum == 0 or i+1 == len(train_loader):\n","                scaler.unscale_(optimizer)\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","                scaler.step(optimizer); scaler.update(); optimizer.zero_grad(set_to_none=True)\n","            running += loss.item() * accum\n","        print(f\"📈 Train Loss: {running/len(train_loader):.4f}\")\n","\n","        # ---- validate ----\n","        model.eval()\n","        val_loss, correct, total = 0., 0, 0\n","        with torch.no_grad():\n","            for x, y in val_loader:\n","                B = y.size(0)\n","                x = x.view(-1, 3, 256, 256).to(device)\n","                y = y.to(device)\n","                with autocast('cuda'):\n","                    out = model(x) / TEMP\n","                    out = out.view(5, B, -1).mean(0)\n","                    out_flip = model(torch.flip(x, dims=[-1])) / TEMP\n","                    out_flip = out_flip.view(5, B, -1).mean(0)\n","                    out = (out + out_flip) / 2\n","                    val_loss += nn.CrossEntropyLoss()(out, y).item()\n","                pred = out.argmax(1)\n","                correct += (pred == y).sum().item()\n","                total += B\n","        val_loss /= len(val_loader)\n","        val_acc = 100 * correct / total\n","        print(f\"🎯 Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), SAVE_BEST)\n","            pat_counter = 0\n","            print(f\"⭐ New best model saved (val_loss={val_loss:.4f})\")\n","        else:\n","            pat_counter += 1\n","            if pat_counter >= patience:\n","                print(\"🛑 Early stopping triggered\")\n","                break\n","        scheduler.step()\n","\n","    model.load_state_dict(torch.load(SAVE_BEST))\n","    torch.save(model, SAVE_FINAL)\n","    with open(SAVE_LABELS, \"w\") as f:\n","        json.dump(breed_names, f)\n","    print(\"✅ Main training finished – best model saved\")\n","\n","# ===================================================================\n","#  2. PSEUDO + HUMAN-IN-THE-LOOP\n","# ===================================================================\n","def predict_image(image_path, temp=TEMP):\n","    model.eval()\n","    img = Image.open(image_path).convert('RGB')\n","    crops = unlabelled_tf(img).to(device)\n","    with torch.no_grad():\n","        with autocast('cuda'):\n","            logits = model(crops) / temp\n","            prob = torch.softmax(logits, dim=1).mean(0)\n","            logits_flip = model(torch.flip(crops, dims=[-1])) / temp\n","            prob_flip = torch.softmax(logits_flip, dim=1).mean(0)\n","            prob = (prob + prob_flip) / 2\n","    top3 = torch.topk(prob, k=3)\n","    return [(breed_names[i], float(p)) for i, p in zip(top3.indices, top3.values)], prob.cpu()\n","\n","def worker_choice(image_path, top3):\n","    print(f\"\\n📸 Image: {os.path.basename(image_path)}\")\n","    for idx, (b, p) in enumerate(top3, 1):\n","        print(f\"  {idx}. {b}  ({p*100:.1f}%)\")\n","    print(\"  0. Skip this image\")\n","    print(\"  4. None of the above\")\n","\n","    while True:\n","        try:\n","            choice = input(\"👉 Choose 0-4: \").strip()\n","            if choice == \"0\":\n","                return \"skip\"\n","            elif choice == \"4\":\n","                return \"none\"\n","            choice = int(choice)\n","            if 1 <= choice <= 3:\n","                return top3[choice-1][0]\n","            else:\n","                print(\"⚠️ Please enter 0, 1, 2, 3, or 4.\")\n","        except ValueError:\n","            print(\"⚠️ Invalid input – please enter a number.\")\n","\n","def create_pseudo_csv():\n","    unlabelled_path = Path(UNLABELLED_DIR)\n","    if not unlabelled_path.exists():\n","        print(f\"❌ Unlabelled directory not found: {UNLABELLED_DIR}\")\n","        pd.DataFrame(columns=['file', 'label', 'confidence', 'type', 'date']).to_csv(PSEUDO_CSV, index=False)\n","        return pd.DataFrame()\n","\n","    # Find image files\n","    image_files = list(unlabelled_path.rglob(\"*.[jJ][pP][gG]\")) + \\\n","                  list(unlabelled_path.rglob(\"*.[jJ][pP][eE][gG]\")) + \\\n","                  list(unlabelled_path.rglob(\"*.[pP][nN][gG]\"))\n","\n","    if len(image_files) == 0:\n","        print(f\"⚠️ No images found in {UNLABELLED_DIR}\")\n","        pd.DataFrame(columns=['file', 'label', 'confidence', 'type', 'date']).to_csv(PSEUDO_CSV, index=False)\n","        return pd.DataFrame()\n","\n","    print(f\"🔍 Found {len(image_files)} images to label...\")\n","    records = []\n","\n","    # Load existing labels (if any) to avoid reprocessing\n","    existing_files = set()\n","    if os.path.exists(PSEUDO_CSV):\n","        try:\n","            existing_df = pd.read_csv(PSEUDO_CSV)\n","            existing_files = set(existing_df['file'].tolist())\n","        except:\n","            pass\n","\n","    for img_path in image_files:\n","        # Skip if already labeled\n","        if str(img_path) in existing_files:\n","            print(f\"⏭️ Already labeled: {img_path.name}\")\n","            continue\n","\n","        try:\n","            top3, soft_prob = predict_image(img_path)\n","            best_breed, best_conf = top3[0]\n","\n","            if best_conf >= SOFT_THR:\n","                # Auto-label with high confidence\n","                records.append({\n","                    'file': str(img_path),\n","                    'label': best_breed,\n","                    'confidence': best_conf,\n","                    'type': 'pseudo',\n","                    'date': datetime.now().isoformat()\n","                })\n","                print(f\"🤖 Auto-labeled: {img_path.name} → {best_breed} ({best_conf:.2f})\")\n","\n","                # Move to processed folder\n","                processed_path = os.path.join(PROCESSED_DIR, img_path.name)\n","                shutil.move(str(img_path), processed_path)\n","\n","            else:\n","                # Get human input for low confidence predictions\n","                chosen = worker_choice(img_path, top3)\n","\n","                if chosen == \"skip\":\n","                    print(f\"⏭️ Skipped: {img_path.name}\")\n","                    # Move to processed folder without labeling\n","                    processed_path = os.path.join(PROCESSED_DIR, img_path.name)\n","                    shutil.move(str(img_path), processed_path)\n","\n","                elif chosen == \"none\":\n","                    print(f\"🏷️ Manual label needed for: {img_path.name}\")\n","                    manual_label = input(\"👉 Enter the breed name manually: \").strip()\n","                    if manual_label and manual_label in breed_names:\n","                        records.append({\n","                            'file': str(img_path),\n","                            'label': manual_label,\n","                            'confidence': 1.0,\n","                            'type': 'human',\n","                            'date': datetime.now().isoformat()\n","                        })\n","                        print(f\"👩‍🌾 Human-labeled: {img_path.name} → {manual_label}\")\n","\n","                        # Move to processed folder\n","                        processed_path = os.path.join(PROCESSED_DIR, img_path.name)\n","                        shutil.move(str(img_path), processed_path)\n","                    else:\n","                        print(f\"❌ Invalid breed name. Skipping: {img_path.name}\")\n","                        # Move to processed folder without labeling\n","                        processed_path = os.path.join(PROCESSED_DIR, img_path.name)\n","                        shutil.move(str(img_path), processed_path)\n","\n","                else:\n","                    records.append({\n","                        'file': str(img_path),\n","                        'label': chosen,\n","                        'confidence': 1.0,\n","                        'type': 'human',\n","                        'date': datetime.now().isoformat()\n","                    })\n","                    print(f\"👩‍🌾 Human-labeled: {img_path.name} → {chosen}\")\n","\n","                    # Move to processed folder\n","                    processed_path = os.path.join(PROCESSED_DIR, img_path.name)\n","                    shutil.move(str(img_path), processed_path)\n","\n","        except Exception as e:\n","            print(f\"❌ Error processing {img_path}: {e}\")\n","            continue\n","\n","    # Merge with existing CSV\n","    if os.path.exists(PSEUDO_CSV) and len(records) > 0:\n","        try:\n","            existing_df = pd.read_csv(PSEUDO_CSV)\n","            new_df = pd.DataFrame(records)\n","            df = pd.concat([existing_df, new_df], ignore_index=True)\n","        except:\n","            df = pd.DataFrame(records)\n","    else:\n","        df = pd.DataFrame(records)\n","\n","    df.to_csv(PSEUDO_CSV, index=False)\n","    print(f\"✅ CSV saved → {len(df)} total labels collected\")\n","    return df\n","\n","# ===================================================================\n","#  3. SOFT-HARD DATASET + RETRAIN\n","# ===================================================================\n","class SoftHardDataset(Dataset):\n","    def __init__(self, csv_file, root, transform, class_to_idx):\n","        if not os.path.exists(csv_file):\n","            self.samples = []\n","            return\n","        try:\n","            self.df = pd.read_csv(csv_file)\n","        except pd.errors.EmptyDataError:\n","            self.df = pd.DataFrame()\n","        self.root = root\n","        self.transform = transform\n","        self.class_to_idx = class_to_idx\n","        self.samples = []\n","        if len(self.df) > 0:\n","            for _, row in self.df.iterrows():\n","                # Check if file exists (it might have been moved to processed folder)\n","                file_path = row['file']\n","                if not os.path.exists(file_path):\n","                    # Try to find it in the processed folder\n","                    processed_path = os.path.join(PROCESSED_DIR, os.path.basename(file_path))\n","                    if os.path.exists(processed_path):\n","                        file_path = processed_path\n","\n","                self.samples.append((file_path, row['label'], row['confidence'], row['type']))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        path, label, conf, typ = self.samples[idx]\n","        img = Image.open(path).convert('RGB')\n","        if self.transform:\n","            img = self.transform(img)\n","        if typ == 'pseudo':\n","            target = torch.zeros(len(self.class_to_idx))\n","            target[self.class_to_idx[label]] = conf\n","            return img, target.float()\n","        else:\n","            return img, self.class_to_idx[label]\n","\n","def retrain_with_new_data(extra_epochs=RETRAIN_EPOCHS):\n","    global accum, grad_clip\n","\n","    print(\"\\n🔄 Checking for pseudo-labels...\")\n","\n","    # Safety check: if CSV doesn't exist or is empty, skip\n","    if not os.path.exists(PSEUDO_CSV):\n","        print(\"⚠️ Pseudo-labels CSV not found — skipping retraining.\")\n","        return\n","\n","    try:\n","        df = pd.read_csv(PSEUDO_CSV)\n","    except pd.errors.EmptyDataError:\n","        print(\"⚠️ Pseudo-labels CSV is empty — skipping retraining.\")\n","        return\n","\n","    if len(df) == 0:\n","        print(\"⚠️ No pseudo-labels collected — skipping retraining.\")\n","        return\n","\n","    print(f\"📥 Found {len(df)} pseudo/human labels — starting retraining...\")\n","\n","    merged_root = \"/content/merged_train\"\n","    os.makedirs(merged_root, exist_ok=True)\n","\n","    # Copy original training data\n","    os.system(f\"cp -r {train_dir}/* {merged_root}/ 2>/dev/null || echo 'Original data copied'\")\n","\n","    # Copy pseudo-labeled images into breed folders\n","    for _, row in df.iterrows():\n","        # Check if file exists in original location or processed folder\n","        src_path = row['file']\n","        if not os.path.exists(src_path):\n","            processed_path = os.path.join(PROCESSED_DIR, os.path.basename(src_path))\n","            if os.path.exists(processed_path):\n","                src_path = processed_path\n","            else:\n","                print(f\"⚠️ Could not find image: {src_path}\")\n","                continue\n","\n","        breed = row['label']\n","        breed_dir = Path(merged_root) / breed\n","        breed_dir.mkdir(exist_ok=True)\n","        dst = breed_dir / os.path.basename(src_path)\n","        if not dst.exists():\n","            shutil.copy(src_path, dst)\n","\n","    # Create dataset and loader\n","    merged_ds = SoftHardDataset(PSEUDO_CSV, merged_root, transform=train_tf,\n","                                class_to_idx=train_ds.class_to_idx)\n","    if len(merged_ds) == 0:\n","        print(\"⚠️ Merged dataset is empty — skipping retraining.\")\n","        return\n","\n","    merged_loader = DataLoader(merged_ds, batch_size=16, shuffle=True,\n","                               num_workers=2, pin_memory=True)\n","\n","    # Add all parameters to optimizer (for fine-tuning)\n","    optimizer.add_param_group({'params': model.parameters(), 'lr': 1e-4})\n","    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","                    optimizer, T_0=len(merged_loader)*3, T_mult=1, eta_min=1e-6)\n","\n","    # Custom criterion for soft/hard labels\n","    def criterion(out, y):\n","        if y.dtype is torch.float32:\n","            return -torch.sum(y * torch.log_softmax(out, dim=1), dim=1).mean()\n","        else:\n","            return nn.CrossEntropyLoss()(out, y)\n","\n","    # Retrain loop\n","    for epoch in range(extra_epochs):\n","        print(f\"\\n+++ 🐄 Pseudo Epoch {epoch+1}/{extra_epochs} +++\")\n","        model.train()\n","        running = 0.\n","        for x, y in merged_loader:\n","            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n","            with autocast('cuda'):\n","                out = model(x)\n","                loss = criterion(out, y) / accum\n","            scaler.scale(loss).backward()\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","            scaler.step(optimizer); scaler.update(); optimizer.zero_grad(set_to_none=True)\n","            running += loss.item() * accum\n","        print(f\"📈 Merged Loss: {running/len(merged_loader):.4f}\")\n","\n","    torch.save(model, \"/content/model_after_pseudo.pth\")\n","    print(\"✅ Pseudo-training finished – model saved\")\n","\n","# ===================================================================\n","#  4. HELPER: LABEL NEW IMAGES ONLY (NO RETRAIN)\n","# ===================================================================\n","def label_new_images_only():\n","    \"\"\"Run ONLY the labeling step — useful when adding new test photos\"\"\"\n","    print(\"📸 Starting NEW IMAGE LABELING only...\")\n","\n","    # Load model if not already loaded\n","    global model, breed_names\n","    if 'model' not in globals() or model is None:\n","        print(\"Loading model...\")\n","        model = torch.load(SAVE_FINAL)\n","        model = model.to(device)\n","        model.eval()\n","        with open(SAVE_LABELS, \"r\") as f:\n","            breed_names = json.load(f)\n","        print(\"Model loaded.\")\n","\n","    df = create_pseudo_csv()  # This will label only NEW images\n","    print(f\"✅ Done labeling. Total labeled images: {len(df) if not df.empty else 0}\")\n","    return df\n","\n","# ===================================================================\n","#  5. EVALUATE SINGLE IMAGE\n","# ===================================================================\n","def evaluate_single_image(image_path=None, image_array=None, camera_index=0):\n","    \"\"\"\n","    Evaluate a single image with the model\n","    Returns: prediction, confidence, top choices\n","    \"\"\"\n","    # Capture/store image if needed\n","    if image_path or image_array is not None or camera_index >= 0:\n","        stored_path = capture_and_store_image(image_path, image_array, camera_index)\n","        if stored_path:\n","            image_path = stored_path\n","\n","    if not image_path or not os.path.exists(image_path):\n","        print(\"❌ No valid image provided\")\n","        return None, None, None\n","\n","    # Make prediction\n","    top3, probs = predict_image(image_path)\n","    prediction, confidence = top3[0]\n","\n","    print(f\"\\n🔍 Prediction for {os.path.basename(image_path)}:\")\n","    print(f\"   Breed: {prediction} (Confidence: {confidence:.2%})\")\n","    print(\"\\n📊 Top choices:\")\n","    for i, (breed, conf) in enumerate(top3, 1):\n","        print(f\"   {i}. {breed}: {conf:.2%}\")\n","\n","    return prediction, confidence, top3\n","\n","# ===================================================================\n","#  6. RUN PIPELINE\n","# ===================================================================\n","if __name__ == \"__main__\":\n","    print(\"🏁 Starting full training pipeline...\")\n","    main_training()               # 1. Train on original data\n","    df = create_pseudo_csv()      # 2. Collect pseudo + human labels\n","    if len(df) > 0:\n","        retrain_with_new_data()   # 3. Retrain on merged set (only if we have labels)\n","    else:\n","        print(\"⏭️ Skipping retraining — no new labels collected.\")\n","\n","    print(\"\\n🎉 PIPELINE COMPLETE!\")\n","    print(\"💾 Final model: /content/breed_model_efficientnet_finetuned.pth\")\n","    print(\"🏷️  Breed names: /content/breed_names.json\")\n","    if os.path.exists(\"/content/model_after_pseudo.pth\"):\n","        print(\"🆙 Upgraded model: /content/model_after_pseudo.pth\")\n","\n","    print(\"\\n💡 TIP: To label NEW images later, run:\")\n","    print(\"   df = label_new_images_only()\")\n","    print(\"   if len(df) > 0:\")\n","    print(\"       retrain_with_new_data()\")\n","\n","    print(\"\\n📸 To evaluate a single image, run:\")\n","    print(\"   evaluate_single_image(image_path='path/to/image.jpg')\")\n","    print(\"   evaluate_single_image(camera_index=0)  # Capture from camera\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"gKfisOdxESa_","executionInfo":{"status":"error","timestamp":1758103613914,"user_tz":-330,"elapsed":716373,"user":{"displayName":"Rakesh Mishra","userId":"09750190647182013057"}},"outputId":"45690e8b-04f3-4290-f31d-17867a2a6c8c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Using cuda\n","🏁 Starting full training pipeline...\n","\n","----- 🐄 Epoch 1/30 -----\n","📈 Train Loss: 2.1953\n","🎯 Val Loss: 1.6545 | Val Acc: 64.19%\n","⭐ New best model saved (val_loss=1.6545)\n","\n","----- 🐄 Epoch 2/30 -----\n","📈 Train Loss: 1.9858\n","🎯 Val Loss: 1.5423 | Val Acc: 68.22%\n","⭐ New best model saved (val_loss=1.5423)\n","\n","----- 🐄 Epoch 3/30 -----\n","📈 Train Loss: 1.9345\n","🎯 Val Loss: 1.5151 | Val Acc: 72.03%\n","⭐ New best model saved (val_loss=1.5151)\n","\n","----- 🐄 Epoch 4/30 -----\n","📈 Train Loss: 1.8796\n","🎯 Val Loss: 1.2695 | Val Acc: 77.33%\n","⭐ New best model saved (val_loss=1.2695)\n","\n","----- 🐄 Epoch 5/30 -----\n","📈 Train Loss: 1.6944\n","🎯 Val Loss: 1.2483 | Val Acc: 76.27%\n","⭐ New best model saved (val_loss=1.2483)\n","\n","----- 🐄 Epoch 6/30 -----\n","📈 Train Loss: 1.6316\n","🎯 Val Loss: 1.1942 | Val Acc: 74.58%\n","⭐ New best model saved (val_loss=1.1942)\n","\n","----- 🐄 Epoch 7/30 -----\n","📈 Train Loss: 1.5284\n","🎯 Val Loss: 1.1339 | Val Acc: 76.91%\n","⭐ New best model saved (val_loss=1.1339)\n","\n","----- 🐄 Epoch 8/30 -----\n","📈 Train Loss: 1.3936\n","🎯 Val Loss: 1.0406 | Val Acc: 79.03%\n","⭐ New best model saved (val_loss=1.0406)\n","\n","----- 🐄 Epoch 9/30 -----\n","📈 Train Loss: 1.4127\n","🎯 Val Loss: 1.1317 | Val Acc: 82.42%\n","\n","----- 🐄 Epoch 10/30 -----\n","📈 Train Loss: 1.2889\n","🎯 Val Loss: 1.1132 | Val Acc: 77.75%\n","\n","----- 🐄 Epoch 11/30 -----\n","📈 Train Loss: 1.3727\n","🎯 Val Loss: 1.0412 | Val Acc: 82.20%\n","\n","----- 🐄 Epoch 12/30 -----\n","📈 Train Loss: 1.3004\n","🎯 Val Loss: 1.0629 | Val Acc: 82.20%\n","\n","----- 🐄 Epoch 13/30 -----\n","📈 Train Loss: 1.2210\n","🎯 Val Loss: 1.0225 | Val Acc: 82.42%\n","⭐ New best model saved (val_loss=1.0225)\n","\n","----- 🐄 Epoch 14/30 -----\n","📈 Train Loss: 1.1745\n","🎯 Val Loss: 1.0538 | Val Acc: 83.26%\n","\n","----- 🐄 Epoch 15/30 -----\n","📈 Train Loss: 1.1943\n","🎯 Val Loss: 1.0096 | Val Acc: 82.42%\n","⭐ New best model saved (val_loss=1.0096)\n","\n","----- 🐄 Epoch 16/30 -----\n","📈 Train Loss: 1.1550\n","🎯 Val Loss: 1.0402 | Val Acc: 81.99%\n","\n","----- 🐄 Epoch 17/30 -----\n","📈 Train Loss: 1.2048\n","🎯 Val Loss: 1.0223 | Val Acc: 80.72%\n","\n","----- 🐄 Epoch 18/30 -----\n","📈 Train Loss: 1.2039\n","🎯 Val Loss: 1.0614 | Val Acc: 85.17%\n","\n","----- 🐄 Epoch 19/30 -----\n","📈 Train Loss: 1.2246\n","🎯 Val Loss: 1.0449 | Val Acc: 80.93%\n","\n","----- 🐄 Epoch 20/30 -----\n","📈 Train Loss: 1.1840\n","🎯 Val Loss: 1.0750 | Val Acc: 80.51%\n","\n","----- 🐄 Epoch 21/30 -----\n","📈 Train Loss: 1.1590\n","🎯 Val Loss: 1.0987 | Val Acc: 82.42%\n","\n","----- 🐄 Epoch 22/30 -----\n","📈 Train Loss: 1.1220\n","🎯 Val Loss: 1.1049 | Val Acc: 79.66%\n","\n","----- 🐄 Epoch 23/30 -----\n","📈 Train Loss: 1.1095\n","🎯 Val Loss: 1.0762 | Val Acc: 83.47%\n","\n","----- 🐄 Epoch 24/30 -----\n","📈 Train Loss: 1.2469\n","🎯 Val Loss: 1.0969 | Val Acc: 81.36%\n","\n","----- 🐄 Epoch 25/30 -----\n","📈 Train Loss: 1.1240\n","🎯 Val Loss: 1.1063 | Val Acc: 79.45%\n","\n","----- 🐄 Epoch 26/30 -----\n","📈 Train Loss: 1.0817\n","🎯 Val Loss: 1.0268 | Val Acc: 80.72%\n","\n","----- 🐄 Epoch 27/30 -----\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2716558760.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🏁 Starting full training pipeline...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0mmain_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# 1. Train on original data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_pseudo_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# 2. Collect pseudo + human labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2716558760.py\u001b[0m in \u001b[0;36mmain_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mrunning\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maccum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"📈 Train Loss: {running/len(train_loader):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"bCV6s_XEESnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BrQWMb2nESqx"},"execution_count":null,"outputs":[]}]}